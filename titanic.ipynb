{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle - Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version history:\n",
    "- v1.0 Initial version\n",
    "- v1.1\n",
    " + Empty ages are filled with a random number between (mean - standard deviation) and (mean + standard deviation)\n",
    " + Convert Pclass in a categorical field\n",
    " + Add noise variables to create a more generic model\n",
    "- v1.2\n",
    " + Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns # Used in distribution graphics\n",
    "import matplotlib.pyplot as plt # Used in distribution graphics\n",
    "\n",
    "# Cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this competition we will work with two files:\n",
    "- train.csv --> The training set\n",
    " + PassengerId - a unique identifier for each passenger\n",
    " + Survived - 0=No 1=Yes\n",
    " + Pclass - 1 = 1st(Upper), 2 = 2nd(Middle), 3 = 3rd(Lower)\n",
    " + Name - name of the passenger\n",
    " + Sex - male/female\n",
    " + Age - age of the passenger in years. Fractional if less than 1. And x.5 if estimated\n",
    " + SibSp - number of siblings/spouse\n",
    " + Parch - number of parents/children\n",
    " + Ticket - ticket number\n",
    " + Fare - price of the ticket\n",
    " + Cabin - cabin number\n",
    " + Embarked - port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "- test.csv --> The test set\n",
    " + PassengerId - a unique identifier for each passenger\n",
    " + Pclass - 1 = 1st(Upper), 2 = 2nd(Middle), 3 = 3rd(Lower)\n",
    " + Name - name of the passenger\n",
    " + Sex - male/female\n",
    " + Age - age of the passenger in years. Fractional if less than 1. And x.5 if estimated\n",
    " + SibSp - number of siblings/spouse\n",
    " + Parch - number of parents/children\n",
    " + Ticket - ticket number\n",
    " + Fare - price of the ticket\n",
    " + Cabin - cabin number\n",
    " + Embarked - port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Miss. Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>F E69</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Drew, Mrs. James Vivian (Lulu Thorne Christian)</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28220</td>\n",
       "      <td>32.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Denkoff, Mr. Mitto</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349225</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>657</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Radeff, Mr. Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349223</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Meyer, Mr. Edgar Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17604</td>\n",
       "      <td>82.1708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cunningham, Mr. Alfred Fleming</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Meyer, Mrs. Edgar Joseph (Leila Saks)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17604</td>\n",
       "      <td>82.1708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bateman, Rev. Robert James</td>\n",
       "      <td>male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O.P. 1166</td>\n",
       "      <td>12.5250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Haas, Miss. Aloisia</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349236</td>\n",
       "      <td>8.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>682</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hassab, Mr. Hammad</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17572</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>D49</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "128          129         1       3   \n",
       "416          417         1       2   \n",
       "335          336         0       3   \n",
       "656          657         0       3   \n",
       "34            35         0       1   \n",
       "413          414         0       2   \n",
       "375          376         1       1   \n",
       "150          151         0       2   \n",
       "293          294         0       3   \n",
       "681          682         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "128                                Peter, Miss. Anna  female   NaN      1   \n",
       "416  Drew, Mrs. James Vivian (Lulu Thorne Christian)  female  34.0      1   \n",
       "335                               Denkoff, Mr. Mitto    male   NaN      0   \n",
       "656                            Radeff, Mr. Alexander    male   NaN      0   \n",
       "34                           Meyer, Mr. Edgar Joseph    male  28.0      1   \n",
       "413                   Cunningham, Mr. Alfred Fleming    male   NaN      0   \n",
       "375            Meyer, Mrs. Edgar Joseph (Leila Saks)  female   NaN      1   \n",
       "150                       Bateman, Rev. Robert James    male  51.0      0   \n",
       "293                              Haas, Miss. Aloisia  female  24.0      0   \n",
       "681                               Hassab, Mr. Hammad    male  27.0      0   \n",
       "\n",
       "     Parch       Ticket     Fare  Cabin Embarked  \n",
       "128      1         2668  22.3583  F E69        C  \n",
       "416      1        28220  32.5000    NaN        S  \n",
       "335      0       349225   7.8958    NaN        S  \n",
       "656      0       349223   7.8958    NaN        S  \n",
       "34       0     PC 17604  82.1708    NaN        C  \n",
       "413      0       239853   0.0000    NaN        S  \n",
       "375      0     PC 17604  82.1708    NaN        C  \n",
       "150      0  S.O.P. 1166  12.5250    NaN        S  \n",
       "293      0       349236   8.8500    NaN        S  \n",
       "681      0     PC 17572  76.7292    D49        C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical description of the data (only numerical fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age is null in some rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical description of the data (categorical fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Turja, Miss. Anna Sofia</td>\n",
       "      <td>male</td>\n",
       "      <td>1601</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex Ticket Cabin Embarked\n",
       "count                       891   891    891   204      889\n",
       "unique                      891     2    681   147        3\n",
       "top     Turja, Miss. Anna Sofia  male   1601    G6        S\n",
       "freq                          1   577      7     4      644"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 rows without Embarked field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         177\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = train_df.isnull().sum()\n",
    "aux[aux>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the test file and keep a backup of both training and test datasets before cleaning them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "train_df_orig = train_df.copy()\n",
    "test_df_orig = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age       86\n",
       "Fare       1\n",
       "Cabin    327\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = test_df.isnull().sum()\n",
    "aux[aux>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unuseful columns in training and test dataset. Columns as Name, Ticket and Cabin are unique (or almost unique) per user, so they don't give information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "test_df = test_df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Fare', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
       "       'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove 2 rows in training dataset with embarked field empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  Fare Embarked\n",
       "61            62         1       1  female  38.0      0      0  80.0      NaN\n",
       "829          830         1       1  female  62.0      0      0  80.0      NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"Embarked\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df[train_df[\"Embarked\"].isnull()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age    177\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = train_df.isnull().sum()\n",
    "aux[aux>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age     86\n",
       "Fare     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = test_df.isnull().sum()\n",
    "aux[aux>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of rows with Age field empty. If we just remove them, we will lose a lot of data, so we need to think in other solution.\n",
    "Our first approach is to fill this empty fields with the mean.  \n",
    "++ v1.1 ++  \n",
    "Empty ages are filled with a random number between (mean - standard deviation) and (mean + standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.64209269662921"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.49293290032352"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Age\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5     True\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "9    False\n",
       "Name: Age, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(train_df[\"Age\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++ v1.1 ++\n",
    "# train_df[\"Age\"]=train_df[\"Age\"].fillna(train_df[\"Age\"].mean())\n",
    "Age_avg = train_df[\"Age\"].mean()\n",
    "Age_std = train_df[\"Age\"].std()\n",
    "Age_null_count = train_df[\"Age\"].isnull().sum()\n",
    "Age_null_random_list = np.random.randint(Age_avg - Age_std, Age_avg + Age_std, size=Age_null_count)\n",
    "train_df[\"Age\"][np.isnan(train_df[\"Age\"])] = Age_null_random_list\n",
    "train_df[\"Age\"] = train_df[\"Age\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex  Age  SibSp  Parch     Fare Embarked\n",
       "0            1         0       3    male   22      1      0   7.2500        S\n",
       "1            2         1       1  female   38      1      0  71.2833        C\n",
       "2            3         1       3  female   26      0      0   7.9250        S\n",
       "3            4         1       1  female   35      1      0  53.1000        S\n",
       "4            5         0       3    male   35      0      0   8.0500        S\n",
       "5            6         0       3    male   35      0      0   8.4583        Q\n",
       "6            7         0       1    male   54      0      0  51.8625        S\n",
       "7            8         0       3    male    2      3      1  21.0750        S\n",
       "8            9         1       3  female   27      0      2  11.1333        S\n",
       "9           10         1       2  female   14      1      0  30.0708        C"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.382452</td>\n",
       "      <td>2.311586</td>\n",
       "      <td>29.467942</td>\n",
       "      <td>0.524184</td>\n",
       "      <td>0.382452</td>\n",
       "      <td>32.096681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>256.998173</td>\n",
       "      <td>0.486260</td>\n",
       "      <td>0.834700</td>\n",
       "      <td>13.539787</td>\n",
       "      <td>1.103705</td>\n",
       "      <td>0.806761</td>\n",
       "      <td>49.697504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>224.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   889.000000  889.000000  889.000000  889.000000  889.000000   \n",
       "mean    446.000000    0.382452    2.311586   29.467942    0.524184   \n",
       "std     256.998173    0.486260    0.834700   13.539787    1.103705   \n",
       "min       1.000000    0.000000    1.000000    0.000000    0.000000   \n",
       "25%     224.000000    0.000000    2.000000   21.000000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.000000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  889.000000  889.000000  \n",
       "mean     0.382452   32.096681  \n",
       "std      0.806761   49.697504  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.895800  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"Age\"].isnull()].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.1750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0           892       3    male  34.5      0      0   7.8292        Q\n",
       "1           893       3  female  47.0      1      0   7.0000        S\n",
       "2           894       2    male  62.0      0      0   9.6875        Q\n",
       "3           895       3    male  27.0      0      0   8.6625        S\n",
       "4           896       3  female  22.0      1      1  12.2875        S\n",
       "5           897       3    male  14.0      0      0   9.2250        S\n",
       "6           898       3  female  30.0      0      0   7.6292        Q\n",
       "7           899       2    male  26.0      1      1  29.0000        S\n",
       "8           900       3  female  18.0      0      0   7.2292        C\n",
       "9           901       3    male  21.0      2      0  24.1500        S\n",
       "10          902       3    male   NaN      0      0   7.8958        S\n",
       "11          903       1    male  46.0      0      0  26.0000        S\n",
       "12          904       1  female  23.0      1      0  82.2667        S\n",
       "13          905       2    male  63.0      1      0  26.0000        S\n",
       "14          906       1  female  47.0      1      0  61.1750        S"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Age\"]=test_df[\"Age\"].fillna(train_df[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>29.467942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.1750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
       "0           892       3    male  34.500000      0      0   7.8292        Q\n",
       "1           893       3  female  47.000000      1      0   7.0000        S\n",
       "2           894       2    male  62.000000      0      0   9.6875        Q\n",
       "3           895       3    male  27.000000      0      0   8.6625        S\n",
       "4           896       3  female  22.000000      1      1  12.2875        S\n",
       "5           897       3    male  14.000000      0      0   9.2250        S\n",
       "6           898       3  female  30.000000      0      0   7.6292        Q\n",
       "7           899       2    male  26.000000      1      1  29.0000        S\n",
       "8           900       3  female  18.000000      0      0   7.2292        C\n",
       "9           901       3    male  21.000000      2      0  24.1500        S\n",
       "10          902       3    male  29.467942      0      0   7.8958        S\n",
       "11          903       1    male  46.000000      0      0  26.0000        S\n",
       "12          904       1  female  23.000000      1      0  82.2667        S\n",
       "13          905       2    male  63.000000      1      0  26.0000        S\n",
       "14          906       1  female  47.000000      1      0  61.1750        S"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.09668087739029"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Fare\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass   Sex   Age  SibSp  Parch  Fare Embarked\n",
       "152         1044       3  male  60.5      0      0   NaN        S"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df[\"Fare\"].isnull()].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Fare\"]=test_df[\"Fare\"].fillna(train_df[\"Fare\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = test_df.isnull().sum()\n",
    "aux[aux>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.096681</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass   Sex   Age  SibSp  Parch       Fare Embarked\n",
       "152         1044       3  male  60.5      0      0  32.096681        S"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df[\"PassengerId\"]==1044]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert categorical fields (Sex and Embarked) in numerical ones. As the ID is numeric we don't need to remove it.  \n",
    "++ v1.1 ++  \n",
    "Convert also Pclass in a categorical field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df[\"Pclass\"]==1,\"Pclass\"]=\"First\"\n",
    "train_df.loc[train_df[\"Pclass\"]==2,\"Pclass\"]=\"Second\"\n",
    "train_df.loc[train_df[\"Pclass\"]==3,\"Pclass\"]=\"Third\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Third</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>First</td>\n",
       "      <td>male</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Third</td>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Second</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex  Age  SibSp  Parch     Fare Embarked\n",
       "0            1         0   Third    male   22      1      0   7.2500        S\n",
       "1            2         1   First  female   38      1      0  71.2833        C\n",
       "2            3         1   Third  female   26      0      0   7.9250        S\n",
       "3            4         1   First  female   35      1      0  53.1000        S\n",
       "4            5         0   Third    male   35      0      0   8.0500        S\n",
       "5            6         0   Third    male   35      0      0   8.4583        Q\n",
       "6            7         0   First    male   54      0      0  51.8625        S\n",
       "7            8         0   Third    male    2      3      1  21.0750        S\n",
       "8            9         1   Third  female   27      0      2  11.1333        S\n",
       "9           10         1  Second  female   14      1      0  30.0708        C"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>889</td>\n",
       "      <td>889</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>491</td>\n",
       "      <td>577</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pclass   Sex Embarked\n",
       "count     889   889      889\n",
       "unique      3     2        3\n",
       "top     Third  male        S\n",
       "freq      491   577      644"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_num = pd.get_dummies(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_First</th>\n",
       "      <th>Pclass_Second</th>\n",
       "      <th>Pclass_Third</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Age  SibSp  Parch     Fare  Pclass_First  \\\n",
       "0            1         0   22      1      0   7.2500             0   \n",
       "1            2         1   38      1      0  71.2833             1   \n",
       "2            3         1   26      0      0   7.9250             0   \n",
       "3            4         1   35      1      0  53.1000             1   \n",
       "4            5         0   35      0      0   8.0500             0   \n",
       "5            6         0   35      0      0   8.4583             0   \n",
       "6            7         0   54      0      0  51.8625             1   \n",
       "7            8         0    2      3      1  21.0750             0   \n",
       "8            9         1   27      0      2  11.1333             0   \n",
       "9           10         1   14      1      0  30.0708             0   \n",
       "\n",
       "   Pclass_Second  Pclass_Third  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
       "0              0             1           0         1           0           0   \n",
       "1              0             0           1         0           1           0   \n",
       "2              0             1           1         0           0           0   \n",
       "3              0             0           1         0           0           0   \n",
       "4              0             1           0         1           0           0   \n",
       "5              0             1           0         1           0           1   \n",
       "6              0             0           0         1           0           0   \n",
       "7              0             1           0         1           0           0   \n",
       "8              0             1           1         0           0           0   \n",
       "9              1             0           1         0           1           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "5           0  \n",
       "6           1  \n",
       "7           1  \n",
       "8           1  \n",
       "9           0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_num.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df[\"Pclass\"]==1,\"Pclass\"]=\"First\"\n",
    "test_df.loc[test_df[\"Pclass\"]==2,\"Pclass\"]=\"Second\"\n",
    "test_df.loc[test_df[\"Pclass\"]==3,\"Pclass\"]=\"Third\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_num = pd.get_dummies(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_First</th>\n",
       "      <th>Pclass_Second</th>\n",
       "      <th>Pclass_Third</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId   Age  SibSp  Parch     Fare  Pclass_First  Pclass_Second  \\\n",
       "0          892  34.5      0      0   7.8292             0              0   \n",
       "1          893  47.0      1      0   7.0000             0              0   \n",
       "2          894  62.0      0      0   9.6875             0              1   \n",
       "3          895  27.0      0      0   8.6625             0              0   \n",
       "4          896  22.0      1      1  12.2875             0              0   \n",
       "5          897  14.0      0      0   9.2250             0              0   \n",
       "6          898  30.0      0      0   7.6292             0              0   \n",
       "7          899  26.0      1      1  29.0000             0              1   \n",
       "8          900  18.0      0      0   7.2292             0              0   \n",
       "9          901  21.0      2      0  24.1500             0              0   \n",
       "\n",
       "   Pclass_Third  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0             1           0         1           0           1           0  \n",
       "1             1           1         0           0           0           1  \n",
       "2             0           0         1           0           1           0  \n",
       "3             1           0         1           0           0           1  \n",
       "4             1           1         0           0           0           1  \n",
       "5             1           0         1           0           0           1  \n",
       "6             1           1         0           0           1           0  \n",
       "7             0           0         1           0           0           1  \n",
       "8             1           1         0           1           0           0  \n",
       "9             1           0         1           0           0           1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_num.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that both training and test dataframes have the same columns. Depending on the values of the categorical fields there could be differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PassengerId', 'Survived', 'Age', 'SibSp', 'Parch', 'Fare',\n",
       "       'Pclass_First', 'Pclass_Second', 'Pclass_Third', 'Sex_female',\n",
       "       'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_df_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PassengerId', 'Age', 'SibSp', 'Parch', 'Fare', 'Pclass_First',\n",
       "       'Pclass_Second', 'Pclass_Third', 'Sex_female', 'Sex_male',\n",
       "       'Embarked_C', 'Embarked_Q', 'Embarked_S'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_df_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_df_num.columns.drop(\"Survived\")) == np.array(test_df_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep a backup of the dataset cleaned and converted to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_num.to_csv(\"train_clean_numeric.csv\", index=None)\n",
    "test_df_num.to_csv(\"test_clean_numeric.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that there are no atypical values (negative, huge values,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_First</th>\n",
       "      <th>Pclass_Second</th>\n",
       "      <th>Pclass_Third</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.382452</td>\n",
       "      <td>29.467942</td>\n",
       "      <td>0.524184</td>\n",
       "      <td>0.382452</td>\n",
       "      <td>32.096681</td>\n",
       "      <td>0.240720</td>\n",
       "      <td>0.206974</td>\n",
       "      <td>0.552306</td>\n",
       "      <td>0.350956</td>\n",
       "      <td>0.649044</td>\n",
       "      <td>0.188976</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.724409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>256.998173</td>\n",
       "      <td>0.486260</td>\n",
       "      <td>13.539787</td>\n",
       "      <td>1.103705</td>\n",
       "      <td>0.806761</td>\n",
       "      <td>49.697504</td>\n",
       "      <td>0.427761</td>\n",
       "      <td>0.405365</td>\n",
       "      <td>0.497536</td>\n",
       "      <td>0.477538</td>\n",
       "      <td>0.477538</td>\n",
       "      <td>0.391710</td>\n",
       "      <td>0.281427</td>\n",
       "      <td>0.447063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>224.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived         Age       SibSp       Parch  \\\n",
       "count   889.000000  889.000000  889.000000  889.000000  889.000000   \n",
       "mean    446.000000    0.382452   29.467942    0.524184    0.382452   \n",
       "std     256.998173    0.486260   13.539787    1.103705    0.806761   \n",
       "min       1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     224.000000    0.000000   21.000000    0.000000    0.000000   \n",
       "50%     446.000000    0.000000   28.000000    0.000000    0.000000   \n",
       "75%     668.000000    1.000000   38.000000    1.000000    0.000000   \n",
       "max     891.000000    1.000000   80.000000    8.000000    6.000000   \n",
       "\n",
       "             Fare  Pclass_First  Pclass_Second  Pclass_Third  Sex_female  \\\n",
       "count  889.000000    889.000000     889.000000    889.000000  889.000000   \n",
       "mean    32.096681      0.240720       0.206974      0.552306    0.350956   \n",
       "std     49.697504      0.427761       0.405365      0.497536    0.477538   \n",
       "min      0.000000      0.000000       0.000000      0.000000    0.000000   \n",
       "25%      7.895800      0.000000       0.000000      0.000000    0.000000   \n",
       "50%     14.454200      0.000000       0.000000      1.000000    0.000000   \n",
       "75%     31.000000      0.000000       0.000000      1.000000    1.000000   \n",
       "max    512.329200      1.000000       1.000000      1.000000    1.000000   \n",
       "\n",
       "         Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "count  889.000000  889.000000  889.000000  889.000000  \n",
       "mean     0.649044    0.188976    0.086614    0.724409  \n",
       "std      0.477538    0.391710    0.281427    0.447063  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000  \n",
       "50%      1.000000    0.000000    0.000000    1.000000  \n",
       "75%      1.000000    0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df_num.shape)\n",
    "train_df_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_First</th>\n",
       "      <th>Pclass_Second</th>\n",
       "      <th>Pclass_Third</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived   Age  SibSp  Parch      Fare  Pclass_First  \\\n",
       "min          1.0       0.0   0.0    0.0    0.0    0.0000           0.0   \n",
       "max        891.0       1.0  80.0    8.0    6.0  512.3292           1.0   \n",
       "\n",
       "     Pclass_Second  Pclass_Third  Sex_female  Sex_male  Embarked_C  \\\n",
       "min            0.0           0.0         0.0       0.0         0.0   \n",
       "max            1.0           1.0         1.0       1.0         1.0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  \n",
       "min         0.0         0.0  \n",
       "max         1.0         1.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_num.describe().loc[[\"min\",\"max\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_First</th>\n",
       "      <th>Pclass_Second</th>\n",
       "      <th>Pclass_Third</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>30.107041</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.618742</td>\n",
       "      <td>0.255981</td>\n",
       "      <td>0.222488</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.244019</td>\n",
       "      <td>0.110048</td>\n",
       "      <td>0.645933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>12.638731</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.840767</td>\n",
       "      <td>0.436934</td>\n",
       "      <td>0.416416</td>\n",
       "      <td>0.500135</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.430019</td>\n",
       "      <td>0.313324</td>\n",
       "      <td>0.478803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>29.467942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId         Age       SibSp       Parch        Fare  \\\n",
       "count   418.000000  418.000000  418.000000  418.000000  418.000000   \n",
       "mean   1100.500000   30.107041    0.447368    0.392344   35.618742   \n",
       "std     120.810458   12.638731    0.896760    0.981429   55.840767   \n",
       "min     892.000000    0.170000    0.000000    0.000000    0.000000   \n",
       "25%     996.250000   23.000000    0.000000    0.000000    7.895800   \n",
       "50%    1100.500000   29.467942    0.000000    0.000000   14.454200   \n",
       "75%    1204.750000   35.750000    1.000000    0.000000   31.500000   \n",
       "max    1309.000000   76.000000    8.000000    9.000000  512.329200   \n",
       "\n",
       "       Pclass_First  Pclass_Second  Pclass_Third  Sex_female    Sex_male  \\\n",
       "count    418.000000     418.000000    418.000000  418.000000  418.000000   \n",
       "mean       0.255981       0.222488      0.521531    0.363636    0.636364   \n",
       "std        0.436934       0.416416      0.500135    0.481622    0.481622   \n",
       "min        0.000000       0.000000      0.000000    0.000000    0.000000   \n",
       "25%        0.000000       0.000000      0.000000    0.000000    0.000000   \n",
       "50%        0.000000       0.000000      1.000000    0.000000    1.000000   \n",
       "75%        1.000000       0.000000      1.000000    1.000000    1.000000   \n",
       "max        1.000000       1.000000      1.000000    1.000000    1.000000   \n",
       "\n",
       "       Embarked_C  Embarked_Q  Embarked_S  \n",
       "count  418.000000  418.000000  418.000000  \n",
       "mean     0.244019    0.110048    0.645933  \n",
       "std      0.430019    0.313324    0.478803  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    1.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_df_num.shape)\n",
    "test_df_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_First</th>\n",
       "      <th>Pclass_Second</th>\n",
       "      <th>Pclass_Third</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.0</td>\n",
       "      <td>76.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId    Age  SibSp  Parch      Fare  Pclass_First  Pclass_Second  \\\n",
       "min        892.0   0.17    0.0    0.0    0.0000           0.0            0.0   \n",
       "max       1309.0  76.00    8.0    9.0  512.3292           1.0            1.0   \n",
       "\n",
       "     Pclass_Third  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "min           0.0         0.0       0.0         0.0         0.0         0.0  \n",
       "max           1.0         1.0       1.0         1.0         1.0         1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_num.describe().loc[[\"min\",\"max\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are very simple, so there is no need to create new synthetic variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x2160 with 33 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bins --> max number of blocks in the graph\n",
    "train_df_num.hist(color='firebrick', bins=30, layout=(11,3), figsize=(15,30));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a peak in the age because we have filled the empty fields with the same value (the average).  \n",
    "++ v1.1 ++  \n",
    "The peak has disappeared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution graphics for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x2880 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clases = np.unique(train_df_num[\"Survived\"])\n",
    "cols = list(train_df_num.columns)\n",
    "cols.remove(\"Survived\")\n",
    "cols.remove(\"PassengerId\")\n",
    "\n",
    "plt.figure(figsize=(15,40))\n",
    "\n",
    "for i,col in enumerate(cols):\n",
    "    plt.subplot(11,3,i+1)\n",
    "    if len(np.unique(train_df_num[col]))>2:\n",
    "        for c in clases:\n",
    "            sns.distplot(train_df_num[train_df_num[\"Survived\"]==c][col], hist=False, kde=True,\n",
    "                         kde_kws = {'shade': True, 'linewidth': 1}, \n",
    "                         label = c)\n",
    "    else:\n",
    "        sns.countplot(x=col, hue=\"Survived\", data=train_df_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a peak of Survived=0 in Pclass_Third=1. It was less likely to survive in third class.\n",
    "- There is a peak of Survived=1 in Parch=0\n",
    "- There is a peak of Survived=0 in Parch=1\n",
    "- There is a peak of Survived=0 in Sex_male=1. It was more likely to survive if you were a woman.\n",
    "- There is a peak of Survived=0 in Embarked_S=1. It was less likely to survive if you embarked in Southamptom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the correlation between parameters and generate a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = train_df_num.corr()\n",
    "corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(corr, cmap=\"bwr\", vmax=1, vmin=-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As expected, Fare and Pclass are related (Pclass_First=1 -> high Fare, Pclass_Third=1 -> low Fare).\n",
    "- As we saw in the distribution graphics, Sex_male and Sex_female are related with Survived.\n",
    "- As we saw in the distribution graphics, Pclass (and therefore Fare) are related with Survived.\n",
    "- Parch and SibSp are also related. If you travel with your children, it's very likely that you also travel with your siblings/spouse (and vice versa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a hierarchically-clustered heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variables ordered by their equality in behaviour\n",
    "sns.clustermap(corr, cmap=\"bwr\", vmax=1, vmin=-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables more related are\n",
    "- Sex_Female and Survived\n",
    "- SibSp and Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived         1.000000\n",
       "Sex_male         0.541585\n",
       "Sex_female       0.541585\n",
       "Pclass_Third     0.320171\n",
       "Pclass_First     0.282368\n",
       "Fare             0.255290\n",
       "Embarked_C       0.169966\n",
       "Embarked_S       0.151777\n",
       "Pclass_Second    0.095002\n",
       "Parch            0.083151\n",
       "Age              0.070487\n",
       "SibSp            0.034040\n",
       "PassengerId      0.005028\n",
       "Embarked_Q       0.004536\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking with variables sorted from more correlated with the target to less correlated (in absulute value)\n",
    "corr[\"Survived\"].abs().sort_values()[::-1] # Sort descendant with stride -1 [begin:end:step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the correlation matrix Sex and Pclass are the most related variables to Survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++ v1.1 ++  \n",
    "Add noise variables to create a more generic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 14)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_num[\"x1\"] = np.random.randn(len(train_df_num))\n",
    "train_df_num[\"x2\"] = np.random.randn(len(train_df_num))\n",
    "train_df_num[\"x3\"] = np.random.randn(len(train_df_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 17)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived         1.000000\n",
       "Sex_male         0.541585\n",
       "Sex_female       0.541585\n",
       "Pclass_Third     0.320171\n",
       "Pclass_First     0.282368\n",
       "Fare             0.255290\n",
       "Embarked_C       0.169966\n",
       "Embarked_S       0.151777\n",
       "Pclass_Second    0.095002\n",
       "Parch            0.083151\n",
       "Age              0.070487\n",
       "SibSp            0.034040\n",
       "x3               0.033178\n",
       "x1               0.030212\n",
       "x2               0.009001\n",
       "PassengerId      0.005028\n",
       "Embarked_Q       0.004536\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2 = train_df_num.corr()\n",
    "corr2[\"Survived\"].abs().sort_values()[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++ v1.1 ++  \n",
    "We also include these noise variables in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 13)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_num[\"x1\"] = np.random.randn(len(test_df_num))\n",
    "test_df_num[\"x2\"] = np.random.randn(len(test_df_num))\n",
    "test_df_num[\"x3\"] = np.random.randn(len(test_df_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 16)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining matrix \"X\" and target \"y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training and test datasets we remove the ID and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training dataframe into an array\n",
    "X      = train_df_num.drop([\"PassengerId\",\"Survived\"], axis=1).values\n",
    "y      = train_df_num[\"Survived\"].values\n",
    "IDs_train = train_df_num[\"PassengerId\"].values\n",
    "\n",
    "# Test:\n",
    "X_test = test_df_num.drop([\"PassengerId\"], axis=1).values\n",
    "IDs_test = test_df_num[\"PassengerId\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Training-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((622, 15), (267, 15), (622,), (267,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3,\n",
    "                                          random_state=1)\n",
    "X_tr.shape, X_te.shape, y_tr.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, data is not standardized (stardard deviation!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.86139743,  1.10209795,  0.83750794, 40.13830573,  0.4207706 ,\n",
       "        0.40774253,  0.49644886,  0.4755827 ,  0.4755827 ,  0.38689569,\n",
       "        0.27435492,  0.44147863,  0.96507863,  1.000564  ,  0.99006276])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are models (like neuronal networks) that need standardized data.  \n",
    "We use Standar Scaler --> X_standardized = (X - X_mean)/X_std  \n",
    "Normalization (values between 0 and 1). Standardization (Mean=0, Standard deviation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#sc.fit(X_tr)\n",
    "sc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 0.42752057,\n",
       "       0.40513681, 0.49725656, 0.47726924, 0.47726924, 0.39148985,\n",
       "       0.28126884, 0.44681137, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_tr_sc = sc.transform(X_tr) # Training\n",
    "#X_te_sc = sc.transform(X_te) # Validation\n",
    "# If we fit and transforms using the same dataset, we can use fit_transform\n",
    "X_sc = sc.transform(X) # Training\n",
    "X_test_sc = sc.transform(X_test) # Test\n",
    "\n",
    "categorical = []\n",
    "#for i in range(X_tr.shape[1]):\n",
    "#    if len(np.unique(X_tr[:,i]))<=2: # Columns with 2 or less different values\n",
    "#        categorical.append(i)\n",
    "for i in range(X.shape[1]):\n",
    "    if len(np.unique(X[:,i]))<=2: # Columns with 2 or less different values\n",
    "        categorical.append(i)\n",
    "\n",
    "#Categorical variables are not standardized. Values recovered from pre-standardized data\n",
    "#X_tr_sc[:,categorical]   = X_tr[:,categorical]\n",
    "#X_te_sc[:,categorical]   = X_te[:,categorical]\n",
    "X_sc[:,categorical]   = X[:,categorical]\n",
    "X_test_sc[:,categorical] = X_test[:,categorical]\n",
    "\n",
    "print(categorical) # Categorical columns are not standardized\n",
    "X_sc.std(axis=0) # Standardized variables has standard deviation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55186579,  0.43135024, -0.47432585, ...,  1.26283019,\n",
       "         1.18321773,  1.4035116 ],\n",
       "       [ 0.63050189,  0.43135024, -0.47432585, ...,  0.54394072,\n",
       "        -1.7429007 ,  0.1798726 ],\n",
       "       [-0.25627387, -0.47519908, -0.47432585, ..., -0.38955881,\n",
       "        -1.39189562, -1.08561976],\n",
       "       ...,\n",
       "       [-0.77355973,  0.43135024,  2.00611934, ..., -1.33655944,\n",
       "        -0.78572752,  0.57661219],\n",
       "       [-0.25627387, -0.47519908, -0.47432585, ..., -0.18170938,\n",
       "         0.20655769,  0.29369071],\n",
       "       [ 0.18711401, -0.47519908, -0.47432585, ...,  1.47457083,\n",
       "         0.21517276,  0.27599708]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.99815168e-17, -3.19704268e-17, -4.79556402e-17,  1.39870617e-16,\n",
       "        2.40719910e-01,  2.06974128e-01,  5.52305962e-01,  3.50956130e-01,\n",
       "        6.49043870e-01,  1.88976378e-01,  8.66141732e-02,  7.24409449e-01,\n",
       "        1.19889101e-17,  3.19704268e-17, -3.19704268e-17])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sc.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 0.42752057,\n",
       "       0.40513681, 0.49725656, 0.47726924, 0.47726924, 0.39148985,\n",
       "       0.28126884, 0.44681137, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sc.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this kind of visualization to see if the points cloud of target=0 and target=1 are overlapped (complex problem) or not (simple problem). We use it only with numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA() # You can use the parameter n_components to keep only the first n components.\n",
    "num_columns=range(0,4) # Numeric columns (number 1,2,3 and 4). Categorical converted into numerical (0 or 1) are not included.\n",
    "pca.fit(X_sc[:,num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((889, 15), (889, 4), (418, 15), (418, 4))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca = pca.transform(X_sc[:,num_columns]) # Only transform (already fit) and with numeric columns.\n",
    "X_test_pca = pca.transform(X_test_sc[:,num_columns])\n",
    "\n",
    "X_sc.shape, X_pca.shape, X_test_sc.shape, X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.55822837e-02, -8.13491423e-01,  8.57471803e-02,\n",
       "        -5.44499792e-01],\n",
       "       [-1.56415007e-04,  9.23108956e-01,  1.23395197e-01,\n",
       "        -7.50773523e-01],\n",
       "       [-6.50617969e-01, -5.37387052e-01,  1.90328691e-01,\n",
       "         7.06402270e-02],\n",
       "       ...,\n",
       "       [ 1.72913755e+00, -4.90903314e-01, -4.97886314e-01,\n",
       "         1.16639799e+00],\n",
       "       [-5.08315093e-01, -2.15164472e-01,  4.60036278e-01,\n",
       "         4.40910589e-02],\n",
       "       [-8.12440663e-01, -2.39219876e-01, -9.10708067e-02,\n",
       "         2.23773934e-02]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.    ,  1.    ,  0.    ,  7.25  ],\n",
       "       [38.    ,  1.    ,  0.    , 71.2833],\n",
       "       [26.    ,  0.    ,  0.    ,  7.925 ],\n",
       "       ...,\n",
       "       [19.    ,  1.    ,  2.    , 23.45  ],\n",
       "       [26.    ,  0.    ,  0.    , 30.    ],\n",
       "       [32.    ,  0.    ,  0.    ,  7.75  ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,num_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can change which PCA components you want to display (0 and 1, 1 and 2,...)\n",
    "comp_horiz=0\n",
    "comp_vert =1\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(X_pca[y==0,comp_horiz],\n",
    "         X_pca[y==0,comp_vert], '.', label=\"Survived=0\",\n",
    "         alpha=0.5, color=\"blue\")\n",
    "plt.plot(X_pca[y==1,comp_horiz],\n",
    "         X_pca[y==1,comp_vert], '.', label=\"Survived=1\",\n",
    "         alpha=0.5, color=\"red\")\n",
    "m_horiz   = X_pca[:,comp_horiz].mean()\n",
    "std_horiz = X_pca[:,comp_horiz].std()\n",
    "m_vert    = X_pca[:,comp_vert].mean()\n",
    "std_vert  = X_pca[:,comp_vert].std()\n",
    "plt.axis([m_horiz-3*std_horiz, m_horiz+3*std_horiz,\n",
    "          m_vert-3*std_vert,   m_vert+3*std_vert])\n",
    "plt.xlabel('principal component '+str(comp_horiz+1))\n",
    "plt.ylabel('principal component '+str(comp_vert+1))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy classifier (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dummy classifier is based on simple rules. Real classifiers should be better than these ones. There are several strategies to follow:\n",
    "    - Most frequent: Just take the most frequent label in the training dataset.\n",
    "    - Stratified: Generates predictions by respecting the training datasets class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring training: 0.6175478065241845\n",
      "Scoring test    : 0.6217228464419475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf_dummy = DummyClassifier(strategy='most_frequent')\n",
    "clf_dummy.fit(X,y)\n",
    "\n",
    "print(\"Scoring training:\", clf_dummy.score(X, y))\n",
    "print(\"Scoring test    :\", clf_dummy.score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring training: 0.5174353205849269\n",
      "Scoring test    : 0.5580524344569289\n"
     ]
    }
   ],
   "source": [
    "clf_dummy = DummyClassifier(strategy='stratified')\n",
    "clf_dummy.fit(X,y)\n",
    "\n",
    "print(\"Scoring training:\", clf_dummy.score(X, y))\n",
    "print(\"Scoring test    :\", clf_dummy.score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'max_iter': 1000, 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr = LogisticRegression()\n",
    "\n",
    "# We will probably have more training examples with Survived=0 than examples with Survived=1. That's why we use StratifiedKFold\n",
    "# because it will ensure that each set contains approximately the same percentage of samples of each target class as the \n",
    "# complete set\n",
    "kfolds=10\n",
    "cv = StratifiedKFold(n_splits = kfolds) \n",
    "\n",
    "params = {\n",
    "    # lower C values means increase the regularization strength (more simple models -->underfit),\n",
    "    # bigger C values means decrease the regularization strength (more complex models -->overfit)\n",
    "    \"C\" : [0.001, 0.01, 0.1, 1, 1.1, 10],\n",
    "    \"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "    \"max_iter\" : [1000, 10000]}\n",
    "\n",
    "# n_jobs=-1 --> Uses all processors\n",
    "# return_train_score=True --> cv_results_ attribute includes training scores\n",
    "grid = GridSearchCV(clf_lr, params, cv = cv, verbose = 0, n_jobs = -1, return_train_score=True)\n",
    "grid = grid.fit(X_sc, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "clf_lr = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 0.78 (+/- 0.01)\n",
      "Accuracy Test: 0.77 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Train: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_train_score'].mean(), grid.cv_results_['std_train_score'].mean() * 2))\n",
    "print(\"Accuracy Test: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_test_score'].mean(), grid.cv_results_['std_test_score'].mean() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3240 candidates, totalling 16200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=-1)]: Done 816 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1168 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1584 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2064 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2608 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3216 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3888 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4624 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5424 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6288 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7216 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8208 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9264 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 10384 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 11568 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 12816 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14128 tasks      | elapsed: 25.1min\n",
      "[Parallel(n_jobs=-1)]: Done 15504 tasks      | elapsed: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16200 out of 16200 | elapsed: 28.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 8, 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_iter': 1000, 'random_state': 1, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier # Multi-layer Perceptron\n",
    "\n",
    "clf_nn = MLPClassifier()\n",
    "\n",
    "# We will probably have more training examples with Survived=0 than examples with Survived=1. That's why we use StratifiedKFold\n",
    "# because it will ensure that each set contains approximately the same percentage of samples of each target class as the \n",
    "# complete set\n",
    "kfolds=5\n",
    "cv = StratifiedKFold(n_splits = kfolds) \n",
    "\n",
    "params = {\n",
    "    # lower C values means increase the regularization strength (more simple models -->underfit),\n",
    "    # bigger C values means decrease the regularization strength (more complex models -->overfit)\n",
    "    # Number of elements in the hidden layer. Number of hidden layers can also be selected\n",
    "    \"hidden_layer_sizes\" : np.arange(5, 10),\n",
    "    \"activation\" : [\"logistic\", \"relu\"],\n",
    "    \"solver\" : [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    # alpha -> L2 penalty (regularization term) parameter.\n",
    "    # L2 -> Ridge (cost function is altered by adding a penalty equivalent to square of the magnitude of the coefficients)\n",
    "    # higher the alpha value, more restriction on the coefficients -> shrinks the coefficients -> reduce the model complexity\n",
    "    # low alpha -> more generalization, coefficients are barely restricted.\n",
    "    \"alpha\" : 10.0 ** -np.arange(1, 5),\n",
    "    \"learning_rate\" : [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    \"learning_rate_init\" : 10.0 ** -np.arange(1, 4),\n",
    "    \"max_iter\" : [200, 1000, 2000],\n",
    "    \"random_state\" : [1]}\n",
    "\n",
    "# n_jobs=-1 --> Uses all processors\n",
    "# return_train_score=True --> cv_results_ attribute includes training scores\n",
    "grid = GridSearchCV(clf_nn, params, cv = cv, verbose = 3, n_jobs = -1, return_train_score=True)\n",
    "grid = grid.fit(X_sc, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "clf_nn = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 0.82 (+/- 0.02)\n",
      "Accuracy Test: 0.75 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Train: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_train_score'].mean(), grid.cv_results_['std_train_score'].mean() * 2))\n",
    "print(\"Accuracy Test: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_test_score'].mean(), grid.cv_results_['std_test_score'].mean() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network without Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.78793602\n",
      "nnet improvement in validation\n",
      "Iteration 2, loss = 0.78294989\n",
      "nnet improvement in validation\n",
      "Iteration 3, loss = 0.77827265\n",
      "nnet improvement in validation\n",
      "Iteration 4, loss = 0.77383832\n",
      "nnet improvement in validation\n",
      "Iteration 5, loss = 0.76954771\n",
      "nnet improvement in validation\n",
      "Iteration 6, loss = 0.76537228\n",
      "nnet improvement in validation\n",
      "Iteration 7, loss = 0.76127904\n",
      "nnet improvement in validation\n",
      "Iteration 8, loss = 0.75726745\n",
      "nnet improvement in validation\n",
      "Iteration 9, loss = 0.75332687\n",
      "nnet improvement in validation\n",
      "Iteration 10, loss = 0.74948145\n",
      "nnet improvement in validation\n",
      "Iteration 11, loss = 0.74572634\n",
      "nnet improvement in validation\n",
      "Iteration 12, loss = 0.74207693\n",
      "nnet improvement in validation\n",
      "Iteration 13, loss = 0.73850130\n",
      "nnet improvement in validation\n",
      "Iteration 14, loss = 0.73498878\n",
      "nnet improvement in validation\n",
      "Iteration 15, loss = 0.73153642\n",
      "nnet improvement in validation\n",
      "Iteration 16, loss = 0.72816414\n",
      "nnet improvement in validation\n",
      "Iteration 17, loss = 0.72488846\n",
      "nnet improvement in validation\n",
      "Iteration 18, loss = 0.72168684\n",
      "nnet improvement in validation\n",
      "Iteration 19, loss = 0.71856896\n",
      "nnet improvement in validation\n",
      "Iteration 20, loss = 0.71552858\n",
      "nnet improvement in validation\n",
      "Iteration 21, loss = 0.71256116\n",
      "nnet improvement in validation\n",
      "Iteration 22, loss = 0.70965635\n",
      "nnet improvement in validation\n",
      "Iteration 23, loss = 0.70681164\n",
      "nnet improvement in validation\n",
      "Iteration 24, loss = 0.70401775\n",
      "nnet improvement in validation\n",
      "Iteration 25, loss = 0.70130012\n",
      "nnet improvement in validation\n",
      "Iteration 26, loss = 0.69862126\n",
      "nnet improvement in validation\n",
      "Iteration 27, loss = 0.69599009\n",
      "nnet improvement in validation\n",
      "Iteration 28, loss = 0.69340239\n",
      "nnet improvement in validation\n",
      "Iteration 29, loss = 0.69085929\n",
      "nnet improvement in validation\n",
      "Iteration 30, loss = 0.68836799\n",
      "nnet improvement in validation\n",
      "Iteration 31, loss = 0.68593375\n",
      "nnet improvement in validation\n",
      "Iteration 32, loss = 0.68353992\n",
      "nnet improvement in validation\n",
      "Iteration 33, loss = 0.68120022\n",
      "nnet improvement in validation\n",
      "Iteration 34, loss = 0.67888867\n",
      "nnet improvement in validation\n",
      "Iteration 35, loss = 0.67659578\n",
      "nnet improvement in validation\n",
      "Iteration 36, loss = 0.67433178\n",
      "nnet improvement in validation\n",
      "Iteration 37, loss = 0.67210310\n",
      "nnet improvement in validation\n",
      "Iteration 38, loss = 0.66990915\n",
      "nnet improvement in validation\n",
      "Iteration 39, loss = 0.66773422\n",
      "nnet improvement in validation\n",
      "Iteration 40, loss = 0.66559367\n",
      "nnet improvement in validation\n",
      "Iteration 41, loss = 0.66347195\n",
      "nnet improvement in validation\n",
      "Iteration 42, loss = 0.66135960\n",
      "nnet improvement in validation\n",
      "Iteration 43, loss = 0.65927057\n",
      "nnet improvement in validation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\albher\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 44, loss = 0.65718664\n",
      "nnet improvement in validation\n",
      "Iteration 45, loss = 0.65511594\n",
      "nnet improvement in validation\n",
      "Iteration 46, loss = 0.65305278\n",
      "nnet improvement in validation\n",
      "Iteration 47, loss = 0.65100721\n",
      "nnet improvement in validation\n",
      "Iteration 48, loss = 0.64898276\n",
      "nnet improvement in validation\n",
      "Iteration 49, loss = 0.64697635\n",
      "nnet improvement in validation\n",
      "Iteration 50, loss = 0.64496664\n",
      "nnet improvement in validation\n",
      "Iteration 51, loss = 0.64296234\n",
      "nnet improvement in validation\n",
      "Iteration 52, loss = 0.64097230\n",
      "nnet improvement in validation\n",
      "Iteration 53, loss = 0.63898348\n",
      "nnet improvement in validation\n",
      "Iteration 54, loss = 0.63699250\n",
      "nnet improvement in validation\n",
      "Iteration 55, loss = 0.63500897\n",
      "nnet improvement in validation\n",
      "Iteration 56, loss = 0.63301753\n",
      "nnet improvement in validation\n",
      "Iteration 57, loss = 0.63102923\n",
      "nnet improvement in validation\n",
      "Iteration 58, loss = 0.62905735\n",
      "nnet improvement in validation\n",
      "Iteration 59, loss = 0.62708782\n",
      "nnet improvement in validation\n",
      "Iteration 60, loss = 0.62512421\n",
      "nnet improvement in validation\n",
      "Iteration 61, loss = 0.62316771\n",
      "nnet improvement in validation\n",
      "Iteration 62, loss = 0.62122188\n",
      "nnet improvement in validation\n",
      "Iteration 63, loss = 0.61928813\n",
      "nnet improvement in validation\n",
      "Iteration 64, loss = 0.61736868\n",
      "nnet improvement in validation\n",
      "Iteration 65, loss = 0.61546390\n",
      "nnet improvement in validation\n",
      "Iteration 66, loss = 0.61357594\n",
      "nnet improvement in validation\n",
      "Iteration 67, loss = 0.61169769\n",
      "nnet improvement in validation\n",
      "Iteration 68, loss = 0.60982910\n",
      "nnet improvement in validation\n",
      "Iteration 69, loss = 0.60798225\n",
      "nnet improvement in validation\n",
      "Iteration 70, loss = 0.60615168\n",
      "nnet improvement in validation\n",
      "Iteration 71, loss = 0.60434519\n",
      "nnet improvement in validation\n",
      "Iteration 72, loss = 0.60254455\n",
      "nnet improvement in validation\n",
      "Iteration 73, loss = 0.60072070\n",
      "nnet improvement in validation\n",
      "Iteration 74, loss = 0.59887447\n",
      "nnet improvement in validation\n",
      "Iteration 75, loss = 0.59701696\n",
      "nnet improvement in validation\n",
      "Iteration 76, loss = 0.59515300\n",
      "nnet improvement in validation\n",
      "Iteration 77, loss = 0.59330699\n",
      "nnet improvement in validation\n",
      "Iteration 78, loss = 0.59147522\n",
      "nnet improvement in validation\n",
      "Iteration 79, loss = 0.58965035\n",
      "nnet improvement in validation\n",
      "Iteration 80, loss = 0.58783324\n",
      "nnet improvement in validation\n",
      "Iteration 81, loss = 0.58600682\n",
      "nnet improvement in validation\n",
      "Iteration 82, loss = 0.58415962\n",
      "nnet improvement in validation\n",
      "Iteration 83, loss = 0.58230101\n",
      "nnet improvement in validation\n",
      "Iteration 84, loss = 0.58044435\n",
      "nnet improvement in validation\n",
      "Iteration 85, loss = 0.57857823\n",
      "nnet improvement in validation\n",
      "Iteration 86, loss = 0.57673004\n",
      "nnet improvement in validation\n",
      "Iteration 87, loss = 0.57490572\n",
      "nnet improvement in validation\n",
      "Iteration 88, loss = 0.57310907\n",
      "nnet improvement in validation\n",
      "Iteration 89, loss = 0.57129990\n",
      "nnet improvement in validation\n",
      "Iteration 90, loss = 0.56945412\n",
      "nnet improvement in validation\n",
      "Iteration 91, loss = 0.56759697\n",
      "nnet improvement in validation\n",
      "Iteration 92, loss = 0.56573785\n",
      "nnet improvement in validation\n",
      "Iteration 93, loss = 0.56386449\n",
      "nnet improvement in validation\n",
      "Iteration 94, loss = 0.56199406\n",
      "nnet improvement in validation\n",
      "Iteration 95, loss = 0.56015230\n",
      "nnet improvement in validation\n",
      "Iteration 96, loss = 0.55834597\n",
      "nnet improvement in validation\n",
      "Iteration 97, loss = 0.55656085\n",
      "nnet improvement in validation\n",
      "Iteration 98, loss = 0.55480804\n",
      "nnet improvement in validation\n",
      "Iteration 99, loss = 0.55311063\n",
      "nnet improvement in validation\n",
      "Iteration 100, loss = 0.55144281\n",
      "nnet improvement in validation\n",
      "Iteration 101, loss = 0.54979647\n",
      "nnet improvement in validation\n",
      "Iteration 102, loss = 0.54819302\n",
      "nnet improvement in validation\n",
      "Iteration 103, loss = 0.54661499\n",
      "nnet improvement in validation\n",
      "Iteration 104, loss = 0.54506050\n",
      "nnet improvement in validation\n",
      "Iteration 105, loss = 0.54352343\n",
      "nnet improvement in validation\n",
      "Iteration 106, loss = 0.54198602\n",
      "nnet improvement in validation\n",
      "Iteration 107, loss = 0.54044837\n",
      "nnet improvement in validation\n",
      "Iteration 108, loss = 0.53890048\n",
      "nnet improvement in validation\n",
      "Iteration 109, loss = 0.53736271\n",
      "nnet improvement in validation\n",
      "Iteration 110, loss = 0.53584731\n",
      "nnet improvement in validation\n",
      "Iteration 111, loss = 0.53435106\n",
      "nnet improvement in validation\n",
      "Iteration 112, loss = 0.53288545\n",
      "nnet improvement in validation\n",
      "Iteration 113, loss = 0.53144452\n",
      "nnet improvement in validation\n",
      "Iteration 114, loss = 0.53001505\n",
      "nnet improvement in validation\n",
      "Iteration 115, loss = 0.52859159\n",
      "nnet improvement in validation\n",
      "Iteration 116, loss = 0.52717947\n",
      "nnet improvement in validation\n",
      "Iteration 117, loss = 0.52578992\n",
      "nnet improvement in validation\n",
      "Iteration 118, loss = 0.52442991\n",
      "nnet improvement in validation\n",
      "Iteration 119, loss = 0.52308617\n",
      "nnet improvement in validation\n",
      "Iteration 120, loss = 0.52176184\n",
      "nnet improvement in validation\n",
      "Iteration 121, loss = 0.52045481\n",
      "nnet improvement in validation\n",
      "Iteration 122, loss = 0.51915045\n",
      "nnet improvement in validation\n",
      "Iteration 123, loss = 0.51785781\n",
      "nnet improvement in validation\n",
      "Iteration 124, loss = 0.51656883\n",
      "nnet improvement in validation\n",
      "Iteration 125, loss = 0.51529219\n",
      "nnet improvement in validation\n",
      "Iteration 126, loss = 0.51403921\n",
      "nnet improvement in validation\n",
      "Iteration 127, loss = 0.51281618\n",
      "nnet improvement in validation\n",
      "Iteration 128, loss = 0.51162097\n",
      "nnet improvement in validation\n",
      "Iteration 129, loss = 0.51044456\n",
      "nnet improvement in validation\n",
      "Iteration 130, loss = 0.50928666\n",
      "nnet improvement in validation\n",
      "Iteration 131, loss = 0.50815329\n",
      "nnet improvement in validation\n",
      "Iteration 132, loss = 0.50705515\n",
      "nnet improvement in validation\n",
      "Iteration 133, loss = 0.50599199\n",
      "nnet improvement in validation\n",
      "Iteration 134, loss = 0.50496431\n",
      "nnet improvement in validation\n",
      "Iteration 135, loss = 0.50396347\n",
      "nnet improvement in validation\n",
      "Iteration 136, loss = 0.50298810\n",
      "nnet improvement in validation\n",
      "Iteration 137, loss = 0.50203685\n",
      "nnet improvement in validation\n",
      "Iteration 138, loss = 0.50109413\n",
      "nnet improvement in validation\n",
      "Iteration 139, loss = 0.50015338\n",
      "nnet improvement in validation\n",
      "Iteration 140, loss = 0.49922024\n",
      "nnet improvement in validation\n",
      "Iteration 141, loss = 0.49828867\n",
      "nnet improvement in validation\n",
      "Iteration 142, loss = 0.49736148\n",
      "nnet improvement in validation\n",
      "Iteration 143, loss = 0.49645259\n",
      "nnet improvement in validation\n",
      "Iteration 144, loss = 0.49556946\n",
      "nnet improvement in validation\n",
      "Iteration 145, loss = 0.49471494\n",
      "nnet improvement in validation\n",
      "Iteration 146, loss = 0.49387442\n",
      "nnet improvement in validation\n",
      "Iteration 147, loss = 0.49305385\n",
      "nnet improvement in validation\n",
      "Iteration 148, loss = 0.49225070\n",
      "nnet improvement in validation\n",
      "Iteration 149, loss = 0.49146848\n",
      "nnet improvement in validation\n",
      "Iteration 150, loss = 0.49070535\n",
      "nnet improvement in validation\n",
      "Iteration 151, loss = 0.48996088\n",
      "nnet improvement in validation\n",
      "Iteration 152, loss = 0.48923045\n",
      "nnet improvement in validation\n",
      "Iteration 153, loss = 0.48851884\n",
      "nnet improvement in validation\n",
      "Iteration 154, loss = 0.48782099\n",
      "nnet improvement in validation\n",
      "Iteration 155, loss = 0.48713511\n",
      "nnet improvement in validation\n",
      "Iteration 156, loss = 0.48646058\n",
      "nnet improvement in validation\n",
      "Iteration 157, loss = 0.48579774\n",
      "nnet improvement in validation\n",
      "Iteration 158, loss = 0.48514757\n",
      "nnet improvement in validation\n",
      "Iteration 159, loss = 0.48450800\n",
      "nnet improvement in validation\n",
      "Iteration 160, loss = 0.48387746\n",
      "nnet improvement in validation\n",
      "Iteration 161, loss = 0.48325274\n",
      "nnet improvement in validation\n",
      "Iteration 162, loss = 0.48264115\n",
      "nnet improvement in validation\n",
      "Iteration 163, loss = 0.48204177\n",
      "nnet improvement in validation\n",
      "Iteration 164, loss = 0.48145725\n",
      "nnet improvement in validation\n",
      "Iteration 165, loss = 0.48088259\n",
      "nnet improvement in validation\n",
      "Iteration 166, loss = 0.48031430\n",
      "nnet improvement in validation\n",
      "Iteration 167, loss = 0.47975531\n",
      "nnet improvement in validation\n",
      "Iteration 168, loss = 0.47920471\n",
      "nnet improvement in validation\n",
      "Iteration 169, loss = 0.47865468\n",
      "nnet improvement in validation\n",
      "Iteration 170, loss = 0.47810727\n",
      "nnet improvement in validation\n",
      "Iteration 171, loss = 0.47756603\n",
      "nnet improvement in validation\n",
      "Iteration 172, loss = 0.47703195\n",
      "nnet improvement in validation\n",
      "Iteration 173, loss = 0.47650600\n",
      "nnet improvement in validation\n",
      "Iteration 174, loss = 0.47598683\n",
      "nnet improvement in validation\n",
      "Iteration 175, loss = 0.47547569\n",
      "nnet improvement in validation\n",
      "Iteration 176, loss = 0.47497283\n",
      "nnet improvement in validation\n",
      "Iteration 177, loss = 0.47448017\n",
      "nnet improvement in validation\n",
      "Iteration 178, loss = 0.47399230\n",
      "nnet improvement in validation\n",
      "Iteration 179, loss = 0.47350628\n",
      "nnet improvement in validation\n",
      "Iteration 180, loss = 0.47302900\n",
      "nnet improvement in validation\n",
      "Iteration 181, loss = 0.47256010\n",
      "nnet improvement in validation\n",
      "Iteration 182, loss = 0.47210635\n",
      "nnet improvement in validation\n",
      "Iteration 183, loss = 0.47166366\n",
      "nnet improvement in validation\n",
      "Iteration 184, loss = 0.47122746\n",
      "nnet improvement in validation\n",
      "Iteration 185, loss = 0.47078890\n",
      "nnet improvement in validation\n",
      "Iteration 186, loss = 0.47035788\n",
      "nnet improvement in validation\n",
      "Iteration 187, loss = 0.46993662\n",
      "nnet improvement in validation\n",
      "Iteration 188, loss = 0.46951941\n",
      "nnet improvement in validation\n",
      "Iteration 189, loss = 0.46910448\n",
      "nnet improvement in validation\n",
      "Iteration 190, loss = 0.46869316\n",
      "nnet improvement in validation\n",
      "Iteration 191, loss = 0.46827922\n",
      "nnet improvement in validation\n",
      "Iteration 192, loss = 0.46786568\n",
      "nnet improvement in validation\n",
      "Iteration 193, loss = 0.46745389\n",
      "nnet improvement in validation\n",
      "Iteration 194, loss = 0.46704882\n",
      "nnet improvement in validation\n",
      "Iteration 195, loss = 0.46665097\n",
      "nnet improvement in validation\n",
      "Iteration 196, loss = 0.46626111\n",
      "nnet improvement in validation\n",
      "Iteration 197, loss = 0.46588101\n",
      "nnet improvement in validation\n",
      "Iteration 198, loss = 0.46550622\n",
      "nnet improvement in validation\n",
      "Iteration 199, loss = 0.46513588\n",
      "nnet improvement in validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200, loss = 0.46477280\n",
      "nnet improvement in validation\n",
      "Iteration 201, loss = 0.46440608\n",
      "nnet improvement in validation\n",
      "Iteration 202, loss = 0.46403649\n",
      "nnet improvement in validation\n",
      "Iteration 203, loss = 0.46366811\n",
      "nnet improvement in validation\n",
      "Iteration 204, loss = 0.46330142\n",
      "nnet improvement in validation\n",
      "Iteration 205, loss = 0.46293790\n",
      "nnet improvement in validation\n",
      "Iteration 206, loss = 0.46257606\n",
      "nnet improvement in validation\n",
      "Iteration 207, loss = 0.46221699\n",
      "nnet improvement in validation\n",
      "Iteration 208, loss = 0.46186140\n",
      "nnet improvement in validation\n",
      "Iteration 209, loss = 0.46151415\n",
      "nnet improvement in validation\n",
      "Iteration 210, loss = 0.46117959\n",
      "nnet improvement in validation\n",
      "Iteration 211, loss = 0.46085306\n",
      "nnet improvement in validation\n",
      "Iteration 212, loss = 0.46053369\n",
      "nnet improvement in validation\n",
      "Iteration 213, loss = 0.46022027\n",
      "nnet improvement in validation\n",
      "Iteration 214, loss = 0.45991626\n",
      "nnet improvement in validation\n",
      "Iteration 215, loss = 0.45962211\n",
      "nnet improvement in validation\n",
      "Iteration 216, loss = 0.45933166\n",
      "nnet improvement in validation\n",
      "Iteration 217, loss = 0.45904855\n",
      "nnet improvement in validation\n",
      "Iteration 218, loss = 0.45877291\n",
      "nnet improvement in validation\n",
      "Iteration 219, loss = 0.45850359\n",
      "nnet improvement in validation\n",
      "Iteration 220, loss = 0.45824053\n",
      "nnet improvement in validation\n",
      "Iteration 221, loss = 0.45797656\n",
      "nnet improvement in validation\n",
      "Iteration 222, loss = 0.45771372\n",
      "nnet improvement in validation\n",
      "Iteration 223, loss = 0.45745344\n",
      "nnet improvement in validation\n",
      "Iteration 224, loss = 0.45719941\n",
      "nnet improvement in validation\n",
      "Iteration 225, loss = 0.45696073\n",
      "nnet improvement in validation\n",
      "Iteration 226, loss = 0.45673225\n",
      "nnet improvement in validation\n",
      "Iteration 227, loss = 0.45651116\n",
      "nnet improvement in validation\n",
      "Iteration 228, loss = 0.45628891\n",
      "nnet improvement in validation\n",
      "Iteration 229, loss = 0.45606646\n",
      "nnet improvement in validation\n",
      "Iteration 230, loss = 0.45584535\n",
      "nnet improvement in validation\n",
      "Iteration 231, loss = 0.45562890\n",
      "nnet improvement in validation\n",
      "Iteration 232, loss = 0.45541740\n",
      "nnet improvement in validation\n",
      "Iteration 233, loss = 0.45520737\n",
      "nnet improvement in validation\n",
      "Iteration 234, loss = 0.45500341\n",
      "nnet improvement in validation\n",
      "Iteration 235, loss = 0.45479976\n",
      "nnet improvement in validation\n",
      "Iteration 236, loss = 0.45458919\n",
      "nnet improvement in validation\n",
      "Iteration 237, loss = 0.45437376\n",
      "nnet improvement in validation\n",
      "Iteration 238, loss = 0.45415388\n",
      "nnet improvement in validation\n",
      "Iteration 239, loss = 0.45392818\n",
      "nnet improvement in validation\n",
      "Iteration 240, loss = 0.45370017\n",
      "Iteration 241, loss = 0.45346607\n",
      "nnet improvement in validation\n",
      "Iteration 242, loss = 0.45322956\n",
      "Iteration 243, loss = 0.45300137\n",
      "Iteration 244, loss = 0.45277024\n",
      "Iteration 245, loss = 0.45253747\n",
      "Iteration 246, loss = 0.45231064\n",
      "Iteration 247, loss = 0.45209022\n",
      "Iteration 248, loss = 0.45187380\n",
      "Iteration 249, loss = 0.45166150\n",
      "Iteration 250, loss = 0.45145398\n",
      "Iteration 251, loss = 0.45124969\n",
      "Iteration 252, loss = 0.45104898\n",
      "Iteration 253, loss = 0.45085207\n",
      "Iteration 254, loss = 0.45065999\n",
      "Iteration 255, loss = 0.45047129\n",
      "Iteration 256, loss = 0.45028794\n",
      "Iteration 257, loss = 0.45010668\n",
      "Iteration 258, loss = 0.44992927\n",
      "Iteration 259, loss = 0.44975019\n",
      "Iteration 260, loss = 0.44957203\n",
      "Iteration 261, loss = 0.44939218\n",
      "Iteration 262, loss = 0.44920320\n",
      "Iteration 263, loss = 0.44901212\n",
      "Iteration 264, loss = 0.44881438\n",
      "Iteration 265, loss = 0.44861447\n",
      "Iteration 266, loss = 0.44840942\n",
      "Iteration 267, loss = 0.44820257\n",
      "Iteration 268, loss = 0.44799675\n",
      "Iteration 269, loss = 0.44779170\n",
      "Iteration 270, loss = 0.44758766\n",
      "Iteration 271, loss = 0.44738071\n",
      "Iteration 272, loss = 0.44717137\n",
      "Iteration 273, loss = 0.44696379\n",
      "Iteration 274, loss = 0.44675445\n",
      "Iteration 275, loss = 0.44654492\n",
      "Iteration 276, loss = 0.44633769\n",
      "Iteration 277, loss = 0.44613147\n",
      "Iteration 278, loss = 0.44592743\n",
      "Iteration 279, loss = 0.44572565\n",
      "Iteration 280, loss = 0.44552116\n",
      "Iteration 281, loss = 0.44530343\n",
      "Iteration 282, loss = 0.44507738\n",
      "Iteration 283, loss = 0.44484683\n",
      "Iteration 284, loss = 0.44461423\n",
      "Iteration 285, loss = 0.44438283\n",
      "Iteration 286, loss = 0.44415299\n",
      "Iteration 287, loss = 0.44392418\n",
      "Iteration 288, loss = 0.44369752\n",
      "Iteration 289, loss = 0.44348434\n",
      "Iteration 290, loss = 0.44327435\n",
      "Iteration 291, loss = 0.44306356\n",
      "Iteration 292, loss = 0.44284844\n",
      "Iteration 293, loss = 0.44263052\n",
      "Iteration 294, loss = 0.44241220\n",
      "Iteration 295, loss = 0.44219406\n",
      "Iteration 296, loss = 0.44198489\n",
      "Iteration 297, loss = 0.44177581\n",
      "Iteration 298, loss = 0.44156185\n",
      "Iteration 299, loss = 0.44134259\n",
      "Iteration 300, loss = 0.44111727\n",
      "Iteration 301, loss = 0.44089212\n",
      "Iteration 302, loss = 0.44067014\n",
      "Iteration 303, loss = 0.44045005\n",
      "Iteration 304, loss = 0.44023017\n",
      "Iteration 305, loss = 0.44001447\n",
      "Iteration 306, loss = 0.43980695\n",
      "Iteration 307, loss = 0.43960085\n",
      "Iteration 308, loss = 0.43939805\n",
      "Iteration 309, loss = 0.43919769\n",
      "Iteration 310, loss = 0.43900290\n",
      "Iteration 311, loss = 0.43881449\n",
      "Iteration 312, loss = 0.43862936\n",
      "Iteration 313, loss = 0.43843566\n",
      "Iteration 314, loss = 0.43823626\n",
      "Iteration 315, loss = 0.43804362\n",
      "Iteration 316, loss = 0.43785913\n",
      "Iteration 317, loss = 0.43767770\n",
      "Iteration 318, loss = 0.43749863\n",
      "Iteration 319, loss = 0.43731800\n",
      "Iteration 320, loss = 0.43713116\n",
      "Iteration 321, loss = 0.43694503\n",
      "Iteration 322, loss = 0.43675966\n",
      "Iteration 323, loss = 0.43658324\n",
      "Iteration 324, loss = 0.43641986\n",
      "Iteration 325, loss = 0.43625231\n",
      "Iteration 326, loss = 0.43607688\n",
      "Iteration 327, loss = 0.43590111\n",
      "Iteration 328, loss = 0.43572658\n",
      "Iteration 329, loss = 0.43555799\n",
      "Iteration 330, loss = 0.43540497\n",
      "Iteration 331, loss = 0.43524836\n",
      "Iteration 332, loss = 0.43507863\n",
      "Iteration 333, loss = 0.43490596\n",
      "Iteration 334, loss = 0.43473537\n",
      "Iteration 335, loss = 0.43455865\n",
      "Iteration 336, loss = 0.43437900\n",
      "Iteration 337, loss = 0.43420146\n",
      "Iteration 338, loss = 0.43404110\n",
      "Iteration 339, loss = 0.43389427\n",
      "Iteration 340, loss = 0.43374342\n",
      "Iteration 341, loss = 0.43359059\n",
      "Iteration 342, loss = 0.43344588\n",
      "Iteration 343, loss = 0.43330409\n",
      "Iteration 344, loss = 0.43316827\n",
      "Iteration 345, loss = 0.43302944\n",
      "Iteration 346, loss = 0.43287200\n",
      "Iteration 347, loss = 0.43271906\n",
      "Iteration 348, loss = 0.43257361\n",
      "Iteration 349, loss = 0.43244141\n",
      "Iteration 350, loss = 0.43231739\n",
      "Iteration 351, loss = 0.43217715\n",
      "Iteration 352, loss = 0.43201911\n",
      "Iteration 353, loss = 0.43186433\n",
      "Iteration 354, loss = 0.43172180\n",
      "Iteration 355, loss = 0.43160291\n",
      "Iteration 356, loss = 0.43149811\n",
      "Iteration 357, loss = 0.43138096\n",
      "Iteration 358, loss = 0.43123473\n",
      "Iteration 359, loss = 0.43108569\n",
      "Iteration 360, loss = 0.43094474\n",
      "Iteration 361, loss = 0.43081367\n",
      "Iteration 362, loss = 0.43069763\n",
      "Iteration 363, loss = 0.43056850\n",
      "Iteration 364, loss = 0.43042870\n",
      "Iteration 365, loss = 0.43028314\n",
      "Iteration 366, loss = 0.43015414\n",
      "Iteration 367, loss = 0.43004304\n",
      "Iteration 368, loss = 0.42993373\n",
      "Iteration 369, loss = 0.42983338\n",
      "Iteration 370, loss = 0.42972902\n",
      "Iteration 371, loss = 0.42960490\n",
      "Iteration 372, loss = 0.42947808\n",
      "Iteration 373, loss = 0.42935505\n",
      "Iteration 374, loss = 0.42924012\n",
      "Iteration 375, loss = 0.42914291\n",
      "Iteration 376, loss = 0.42903844\n",
      "Iteration 377, loss = 0.42893280\n",
      "Iteration 378, loss = 0.42882759\n",
      "Iteration 379, loss = 0.42872285\n",
      "Iteration 380, loss = 0.42862622\n",
      "Iteration 381, loss = 0.42852493\n",
      "Iteration 382, loss = 0.42841611\n",
      "Iteration 383, loss = 0.42831001\n",
      "Iteration 384, loss = 0.42822010\n",
      "Iteration 385, loss = 0.42815190\n",
      "Iteration 386, loss = 0.42807097\n",
      "Iteration 387, loss = 0.42796729\n",
      "Iteration 388, loss = 0.42784686\n",
      "Iteration 389, loss = 0.42773591\n",
      "Iteration 390, loss = 0.42764190\n",
      "Iteration 391, loss = 0.42756126\n",
      "Iteration 392, loss = 0.42748399\n",
      "Iteration 393, loss = 0.42740728\n",
      "Iteration 394, loss = 0.42732620\n",
      "Iteration 395, loss = 0.42722657\n",
      "Iteration 396, loss = 0.42713243\n",
      "Iteration 397, loss = 0.42705554\n",
      "Iteration 398, loss = 0.42698214\n",
      "Iteration 399, loss = 0.42690452\n",
      "Iteration 400, loss = 0.42681742\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 401, loss = 0.42673326\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 402, loss = 0.42664972\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 403, loss = 0.42657225\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 404, loss = 0.42651214\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 405, loss = 0.42645028\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 406, loss = 0.42638919\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 407, loss = 0.42631628\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 408, loss = 0.42623341\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 409, loss = 0.42616622\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 410, loss = 0.42609176\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 411, loss = 0.42600972\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 412, loss = 0.42592795\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 413, loss = 0.42585934\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 414, loss = 0.42579386\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 415, loss = 0.42570792\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 416, loss = 0.42562412\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 417, loss = 0.42556140\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 418, loss = 0.42549256\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 419, loss = 0.42542427\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 420, loss = 0.42535465\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 421, loss = 0.42527644\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 422, loss = 0.42518584\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 423, loss = 0.42510610\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 424, loss = 0.42503750\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 425, loss = 0.42496831\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 426, loss = 0.42487819\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 427, loss = 0.42478913\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 428, loss = 0.42470125\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 429, loss = 0.42460521\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 430, loss = 0.42451896\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 431, loss = 0.42444112\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 432, loss = 0.42434940\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 433, loss = 0.42424658\n",
      "Iteration 434, loss = 0.42415200\n",
      "Iteration 435, loss = 0.42407403\n",
      "Iteration 436, loss = 0.42401142\n",
      "Iteration 437, loss = 0.42393866\n",
      "Iteration 438, loss = 0.42385394\n",
      "Iteration 439, loss = 0.42376774\n",
      "Iteration 440, loss = 0.42367530\n",
      "Iteration 441, loss = 0.42358618\n",
      "Iteration 442, loss = 0.42350190\n",
      "Iteration 443, loss = 0.42341918\n",
      "Iteration 444, loss = 0.42334099\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 445, loss = 0.42326978\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 446, loss = 0.42318998\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 447, loss = 0.42310582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 448, loss = 0.42300758\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 449, loss = 0.42290640\n",
      "Iteration 450, loss = 0.42281126\n",
      "Iteration 451, loss = 0.42272539\n",
      "Iteration 452, loss = 0.42264643\n",
      "Iteration 453, loss = 0.42257063\n",
      "Iteration 454, loss = 0.42249892\n",
      "Iteration 455, loss = 0.42243115\n",
      "Iteration 456, loss = 0.42234507\n",
      "Iteration 457, loss = 0.42224952\n",
      "Iteration 458, loss = 0.42215425\n",
      "Iteration 459, loss = 0.42207594\n",
      "Iteration 460, loss = 0.42199681\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 461, loss = 0.42190527\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 462, loss = 0.42182056\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 463, loss = 0.42174976\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 464, loss = 0.42166470\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 465, loss = 0.42156999\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 466, loss = 0.42148313\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 467, loss = 0.42140298\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 468, loss = 0.42131468\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 469, loss = 0.42121096\n",
      "Iteration 470, loss = 0.42111346\n",
      "Iteration 471, loss = 0.42103529\n",
      "Iteration 472, loss = 0.42096426\n",
      "Iteration 473, loss = 0.42087508\n",
      "Iteration 474, loss = 0.42078182\n",
      "Iteration 475, loss = 0.42070659\n",
      "Iteration 476, loss = 0.42063797\n",
      "Iteration 477, loss = 0.42055788\n",
      "Iteration 478, loss = 0.42047626\n",
      "Iteration 479, loss = 0.42039169\n",
      "Iteration 480, loss = 0.42032252\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 481, loss = 0.42026746\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 482, loss = 0.42019708\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 483, loss = 0.42010715\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 484, loss = 0.42000807\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 485, loss = 0.41991091\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 486, loss = 0.41980667\n",
      "Iteration 487, loss = 0.41971038\n",
      "Iteration 488, loss = 0.41962937\n",
      "Iteration 489, loss = 0.41955165\n",
      "Iteration 490, loss = 0.41947013\n",
      "Iteration 491, loss = 0.41937401\n",
      "Iteration 492, loss = 0.41927436\n",
      "Iteration 493, loss = 0.41918915\n",
      "Iteration 494, loss = 0.41911061\n",
      "Iteration 495, loss = 0.41900857\n",
      "Iteration 496, loss = 0.41891498\n",
      "Iteration 497, loss = 0.41883861\n",
      "Iteration 498, loss = 0.41876090\n",
      "Iteration 499, loss = 0.41869339\n",
      "Iteration 500, loss = 0.41861011\n",
      "Iteration 501, loss = 0.41852355\n",
      "Iteration 502, loss = 0.41845010\n",
      "Iteration 503, loss = 0.41837606\n",
      "Iteration 504, loss = 0.41830470\n",
      "Iteration 505, loss = 0.41823632\n",
      "Iteration 506, loss = 0.41816662\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 507, loss = 0.41809052\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 508, loss = 0.41801057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 509, loss = 0.41793145\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 510, loss = 0.41785301\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 511, loss = 0.41777157\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 512, loss = 0.41770028\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 513, loss = 0.41762682\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 514, loss = 0.41755193\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 515, loss = 0.41746858\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 516, loss = 0.41737889\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 517, loss = 0.41730471\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 518, loss = 0.41722752\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 519, loss = 0.41714808\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 520, loss = 0.41705937\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 521, loss = 0.41698292\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 522, loss = 0.41691404\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 523, loss = 0.41683889\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 524, loss = 0.41675353\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 525, loss = 0.41665786\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 526, loss = 0.41656650\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 527, loss = 0.41647697\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 528, loss = 0.41639658\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 529, loss = 0.41632985\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 530, loss = 0.41625566\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 531, loss = 0.41618115\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 532, loss = 0.41610467\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 533, loss = 0.41601940\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 534, loss = 0.41595170\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 535, loss = 0.41588142\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 536, loss = 0.41580213\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 537, loss = 0.41572573\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 538, loss = 0.41565910\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 539, loss = 0.41559503\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 540, loss = 0.41552211\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 541, loss = 0.41543895\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 542, loss = 0.41536887\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 543, loss = 0.41531147\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 544, loss = 0.41525469\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 545, loss = 0.41519154\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 546, loss = 0.41511408\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 547, loss = 0.41504216\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 548, loss = 0.41497782\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 549, loss = 0.41492938\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 550, loss = 0.41487636\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 551, loss = 0.41480405\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 552, loss = 0.41473366\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 553, loss = 0.41467379\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 554, loss = 0.41462745\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 555, loss = 0.41456922\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 556, loss = 0.41449822\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 557, loss = 0.41443912\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 558, loss = 0.41439845\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 559, loss = 0.41435306\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 560, loss = 0.41429111\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 561, loss = 0.41420798\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 562, loss = 0.41413622\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 563, loss = 0.41408242\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 564, loss = 0.41402769\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 565, loss = 0.41396264\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 566, loss = 0.41388590\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 567, loss = 0.41381737\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 568, loss = 0.41375437\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 569, loss = 0.41367161\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 570, loss = 0.41358160\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 571, loss = 0.41349339\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 572, loss = 0.41340186\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 573, loss = 0.41331214\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 574, loss = 0.41322534\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 575, loss = 0.41313579\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 576, loss = 0.41305870\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 577, loss = 0.41298323\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 578, loss = 0.41288850\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 579, loss = 0.41280593\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 580, loss = 0.41273805\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 581, loss = 0.41267440\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 582, loss = 0.41260758\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 583, loss = 0.41253070\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 584, loss = 0.41245451\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 585, loss = 0.41237362\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 586, loss = 0.41229935\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 587, loss = 0.41222440\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 588, loss = 0.41214530\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 589, loss = 0.41207699\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 590, loss = 0.41200384\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 591, loss = 0.41193414\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 592, loss = 0.41187211\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 593, loss = 0.41178924\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 594, loss = 0.41169609\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 595, loss = 0.41160156\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 596, loss = 0.41154065\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 597, loss = 0.41148288\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 598, loss = 0.41140740\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 599, loss = 0.41132094\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 600, loss = 0.41123101\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 601, loss = 0.41114354\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 602, loss = 0.41107620\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 603, loss = 0.41101885\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 604, loss = 0.41095265\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 605, loss = 0.41087204\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 606, loss = 0.41078524\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 607, loss = 0.41072571\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 608, loss = 0.41066670\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 609, loss = 0.41058482\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 610, loss = 0.41050551\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 611, loss = 0.41043301\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 612, loss = 0.41037680\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 613, loss = 0.41031062\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 614, loss = 0.41022468\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 615, loss = 0.41015737\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 616, loss = 0.41009990\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 617, loss = 0.41003622\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 618, loss = 0.40996408\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 619, loss = 0.40991069\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 620, loss = 0.40984895\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 621, loss = 0.40977023\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 622, loss = 0.40969894\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 623, loss = 0.40963726\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 624, loss = 0.40959353\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 625, loss = 0.40954300\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 626, loss = 0.40947317\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 627, loss = 0.40940702\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 628, loss = 0.40935745\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 629, loss = 0.40930649\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 630, loss = 0.40924495\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 631, loss = 0.40918250\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 632, loss = 0.40913483\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 633, loss = 0.40909418\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 634, loss = 0.40905817\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 635, loss = 0.40899934\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 636, loss = 0.40893755\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 637, loss = 0.40889826\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 638, loss = 0.40885826\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 639, loss = 0.40879199\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 640, loss = 0.40873000\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 641, loss = 0.40868353\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 642, loss = 0.40865435\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 643, loss = 0.40861229\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 644, loss = 0.40854224\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 645, loss = 0.40847689\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 646, loss = 0.40841960\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 647, loss = 0.40835227\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 648, loss = 0.40825781\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 649, loss = 0.40818462\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 650, loss = 0.40812205\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 651, loss = 0.40806795\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 652, loss = 0.40799746\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 653, loss = 0.40791898\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 654, loss = 0.40784323\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 655, loss = 0.40777816\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 656, loss = 0.40769523\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 657, loss = 0.40759516\n",
      "Iteration 658, loss = 0.40750294\n",
      "Iteration 659, loss = 0.40743066\n",
      "Iteration 660, loss = 0.40736617\n",
      "Iteration 661, loss = 0.40728216\n",
      "Iteration 662, loss = 0.40719129\n",
      "Iteration 663, loss = 0.40709629\n",
      "Iteration 664, loss = 0.40703712\n",
      "Iteration 665, loss = 0.40697086\n",
      "Iteration 666, loss = 0.40688571\n",
      "Iteration 667, loss = 0.40678586\n",
      "Iteration 668, loss = 0.40668778\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 669, loss = 0.40660470\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 670, loss = 0.40652499\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 671, loss = 0.40643554\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 672, loss = 0.40632592\n",
      "Iteration 673, loss = 0.40623886\n",
      "Iteration 674, loss = 0.40616759\n",
      "Iteration 675, loss = 0.40607840\n",
      "Iteration 676, loss = 0.40597101\n",
      "Iteration 677, loss = 0.40585780\n",
      "Iteration 678, loss = 0.40577457\n",
      "Iteration 679, loss = 0.40569595\n",
      "Iteration 680, loss = 0.40560347\n",
      "Iteration 681, loss = 0.40550293\n",
      "Iteration 682, loss = 0.40539555\n",
      "Iteration 683, loss = 0.40528815\n",
      "Iteration 684, loss = 0.40518442\n",
      "Iteration 685, loss = 0.40508322\n",
      "Iteration 686, loss = 0.40502297\n",
      "Iteration 687, loss = 0.40495192\n",
      "Iteration 688, loss = 0.40485395\n",
      "Iteration 689, loss = 0.40475955\n",
      "Iteration 690, loss = 0.40468809\n",
      "Iteration 691, loss = 0.40463024\n",
      "Iteration 692, loss = 0.40455185\n",
      "Iteration 693, loss = 0.40446507\n",
      "Iteration 694, loss = 0.40437947\n",
      "Iteration 695, loss = 0.40429661\n",
      "Iteration 696, loss = 0.40422396\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 697, loss = 0.40416122\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 698, loss = 0.40411294\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 699, loss = 0.40405422\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 700, loss = 0.40397215\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 701, loss = 0.40389736\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 702, loss = 0.40383935\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 703, loss = 0.40378645\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 704, loss = 0.40372287\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 705, loss = 0.40365816\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 706, loss = 0.40358659\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 707, loss = 0.40352646\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 708, loss = 0.40346604\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 709, loss = 0.40339723\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 710, loss = 0.40334389\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 711, loss = 0.40329152\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 712, loss = 0.40322102\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 713, loss = 0.40316865\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 714, loss = 0.40309627\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 715, loss = 0.40301817\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 716, loss = 0.40293160\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 717, loss = 0.40286415\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 718, loss = 0.40280729\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 719, loss = 0.40277074\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 720, loss = 0.40272778\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 721, loss = 0.40263848\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 722, loss = 0.40253485\n",
      "Iteration 723, loss = 0.40245022\n",
      "Iteration 724, loss = 0.40239969\n",
      "Iteration 725, loss = 0.40235212\n",
      "Iteration 726, loss = 0.40229553\n",
      "Iteration 727, loss = 0.40223962\n",
      "Iteration 728, loss = 0.40215002\n",
      "Iteration 729, loss = 0.40201771\n",
      "Iteration 730, loss = 0.40184664\n",
      "Iteration 731, loss = 0.40167534\n",
      "Iteration 732, loss = 0.40151815\n",
      "Iteration 733, loss = 0.40138779\n",
      "Iteration 734, loss = 0.40124368\n",
      "Iteration 735, loss = 0.40108337\n",
      "Iteration 736, loss = 0.40093452\n",
      "Iteration 737, loss = 0.40079932\n",
      "Iteration 738, loss = 0.40067489\n",
      "Iteration 739, loss = 0.40055054\n",
      "Iteration 740, loss = 0.40042994\n",
      "Iteration 741, loss = 0.40031476\n",
      "Iteration 742, loss = 0.40021711\n",
      "Iteration 743, loss = 0.40011795\n",
      "Iteration 744, loss = 0.40002466\n",
      "Iteration 745, loss = 0.39991603\n",
      "Iteration 746, loss = 0.39981792\n",
      "Iteration 747, loss = 0.39973806\n",
      "Iteration 748, loss = 0.39966145\n",
      "Iteration 749, loss = 0.39960021\n",
      "Iteration 750, loss = 0.39953299\n",
      "Iteration 751, loss = 0.39945027\n",
      "Iteration 752, loss = 0.39937634\n",
      "Iteration 753, loss = 0.39930597\n",
      "Iteration 754, loss = 0.39923209\n",
      "Iteration 755, loss = 0.39916311\n",
      "Iteration 756, loss = 0.39909702\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 757, loss = 0.39901946\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 758, loss = 0.39892856\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 759, loss = 0.39884519\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 760, loss = 0.39878128\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 761, loss = 0.39872220\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 762, loss = 0.39865633\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 763, loss = 0.39855207\n",
      "Iteration 764, loss = 0.39844124\n",
      "Iteration 765, loss = 0.39834148\n",
      "Iteration 766, loss = 0.39826919\n",
      "Iteration 767, loss = 0.39818989\n",
      "Iteration 768, loss = 0.39809625\n",
      "Iteration 769, loss = 0.39799076\n",
      "Iteration 770, loss = 0.39791019\n",
      "Iteration 771, loss = 0.39783375\n",
      "Iteration 772, loss = 0.39775689\n",
      "Iteration 773, loss = 0.39767954\n",
      "Iteration 774, loss = 0.39757420\n",
      "Iteration 775, loss = 0.39745806\n",
      "Iteration 776, loss = 0.39733972\n",
      "Iteration 777, loss = 0.39723629\n",
      "Iteration 778, loss = 0.39717005\n",
      "Iteration 779, loss = 0.39709542\n",
      "Iteration 780, loss = 0.39698762\n",
      "Iteration 781, loss = 0.39688058\n",
      "Iteration 782, loss = 0.39679099\n",
      "Iteration 783, loss = 0.39670692\n",
      "Iteration 784, loss = 0.39661914\n",
      "Iteration 785, loss = 0.39652582\n",
      "Iteration 786, loss = 0.39642651\n",
      "Iteration 787, loss = 0.39634739\n",
      "Iteration 788, loss = 0.39627332\n",
      "Iteration 789, loss = 0.39619712\n",
      "Iteration 790, loss = 0.39612899\n",
      "Iteration 791, loss = 0.39604288\n",
      "Iteration 792, loss = 0.39595856\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 793, loss = 0.39589050\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 794, loss = 0.39582804\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 795, loss = 0.39575671\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 796, loss = 0.39568700\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 797, loss = 0.39561943\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 798, loss = 0.39554015\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 799, loss = 0.39546646\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 800, loss = 0.39540366\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 801, loss = 0.39532906\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 802, loss = 0.39526171\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 803, loss = 0.39520798\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 804, loss = 0.39512992\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 805, loss = 0.39503673\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 806, loss = 0.39495384\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 807, loss = 0.39488275\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 808, loss = 0.39482249\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 809, loss = 0.39475129\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 810, loss = 0.39467057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 811, loss = 0.39461543\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 812, loss = 0.39453583\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 813, loss = 0.39443809\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 814, loss = 0.39436153\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 815, loss = 0.39428914\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 816, loss = 0.39420605\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 817, loss = 0.39412988\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 818, loss = 0.39406438\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 819, loss = 0.39400514\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 820, loss = 0.39391789\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 821, loss = 0.39382975\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 822, loss = 0.39377892\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 823, loss = 0.39372294\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 824, loss = 0.39364005\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 825, loss = 0.39355813\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 826, loss = 0.39347049\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 827, loss = 0.39341595\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 828, loss = 0.39336324\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 829, loss = 0.39328910\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 830, loss = 0.39320981\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 831, loss = 0.39314606\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 832, loss = 0.39307453\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 833, loss = 0.39300509\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 834, loss = 0.39296739\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 835, loss = 0.39292780\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 836, loss = 0.39285669\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 837, loss = 0.39279366\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 838, loss = 0.39276023\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 839, loss = 0.39270959\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 840, loss = 0.39262818\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 841, loss = 0.39255728\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 842, loss = 0.39250543\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 843, loss = 0.39245138\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 844, loss = 0.39239453\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 845, loss = 0.39233978\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 846, loss = 0.39230940\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 847, loss = 0.39226750\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 848, loss = 0.39219372\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 849, loss = 0.39212075\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 850, loss = 0.39206384\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 851, loss = 0.39202148\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 852, loss = 0.39199186\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 853, loss = 0.39193387\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 854, loss = 0.39187067\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 855, loss = 0.39181627\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 856, loss = 0.39175880\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 857, loss = 0.39171107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 858, loss = 0.39166774\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 859, loss = 0.39160285\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 860, loss = 0.39153185\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 861, loss = 0.39147111\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 862, loss = 0.39141434\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 863, loss = 0.39136252\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 864, loss = 0.39130156\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 865, loss = 0.39124923\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 866, loss = 0.39122623\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 867, loss = 0.39118330\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 868, loss = 0.39113571\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 869, loss = 0.39107715\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 870, loss = 0.39100646\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 871, loss = 0.39095443\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 872, loss = 0.39091465\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 873, loss = 0.39088990\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 874, loss = 0.39084451\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 875, loss = 0.39078801\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 876, loss = 0.39074023\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 877, loss = 0.39067604\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 878, loss = 0.39061343\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 879, loss = 0.39056680\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 880, loss = 0.39052575\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 881, loss = 0.39047606\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 882, loss = 0.39042023\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 883, loss = 0.39039307\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 884, loss = 0.39036158\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 885, loss = 0.39029709\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 886, loss = 0.39023736\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 887, loss = 0.39017168\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 888, loss = 0.39011428\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 889, loss = 0.39009282\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 890, loss = 0.39005712\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 891, loss = 0.39000814\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 892, loss = 0.38995193\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 893, loss = 0.38992822\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 894, loss = 0.38991494\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 895, loss = 0.38986866\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 896, loss = 0.38981458\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 897, loss = 0.38976685\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 898, loss = 0.38973137\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 899, loss = 0.38968491\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 900, loss = 0.38963186\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 901, loss = 0.38959289\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 902, loss = 0.38954880\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 903, loss = 0.38950300\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 904, loss = 0.38944899\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 905, loss = 0.38941710\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 906, loss = 0.38936981\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 907, loss = 0.38932842\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 908, loss = 0.38929137\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 909, loss = 0.38923312\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 910, loss = 0.38918142\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 911, loss = 0.38913957\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 912, loss = 0.38912578\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 913, loss = 0.38910233\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 914, loss = 0.38904219\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 915, loss = 0.38899166\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 916, loss = 0.38894308\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 917, loss = 0.38891015\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 918, loss = 0.38885840\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 919, loss = 0.38880554\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 920, loss = 0.38876469\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 921, loss = 0.38872546\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 922, loss = 0.38867420\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 923, loss = 0.38861312\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 924, loss = 0.38857236\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 925, loss = 0.38851710\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 926, loss = 0.38848596\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 927, loss = 0.38845211\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 928, loss = 0.38840315\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 929, loss = 0.38835806\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 930, loss = 0.38831225\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 931, loss = 0.38827051\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 932, loss = 0.38823091\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 933, loss = 0.38818382\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 934, loss = 0.38814790\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 935, loss = 0.38810548\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 936, loss = 0.38804656\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 937, loss = 0.38799848\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 938, loss = 0.38796431\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 939, loss = 0.38793612\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 940, loss = 0.38790194\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 941, loss = 0.38783700\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 942, loss = 0.38779483\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 943, loss = 0.38776726\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 944, loss = 0.38771885\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 945, loss = 0.38766669\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 946, loss = 0.38763782\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 947, loss = 0.38759272\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 948, loss = 0.38755295\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 949, loss = 0.38751334\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 950, loss = 0.38747626\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 951, loss = 0.38744031\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 952, loss = 0.38739516\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 953, loss = 0.38732262\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 954, loss = 0.38724980\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 955, loss = 0.38719406\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 956, loss = 0.38715501\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 957, loss = 0.38712602\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 958, loss = 0.38708021\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 959, loss = 0.38703222\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 960, loss = 0.38698382\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 961, loss = 0.38693726\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 962, loss = 0.38689998\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 963, loss = 0.38685094\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 964, loss = 0.38679941\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 965, loss = 0.38675630\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 966, loss = 0.38672664\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 967, loss = 0.38669211\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 968, loss = 0.38664245\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 969, loss = 0.38657231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 970, loss = 0.38652500\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 971, loss = 0.38650728\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 972, loss = 0.38647129\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 973, loss = 0.38640456\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 974, loss = 0.38634185\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 975, loss = 0.38628642\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 976, loss = 0.38623628\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 977, loss = 0.38621423\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 978, loss = 0.38618517\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 979, loss = 0.38613826\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 980, loss = 0.38608061\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 981, loss = 0.38602596\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 982, loss = 0.38597619\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 983, loss = 0.38593029\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 984, loss = 0.38588535\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 985, loss = 0.38584039\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 986, loss = 0.38580789\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 987, loss = 0.38576729\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 988, loss = 0.38572720\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 989, loss = 0.38566212\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 990, loss = 0.38560602\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 991, loss = 0.38555415\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 992, loss = 0.38553327\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 993, loss = 0.38550915\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 994, loss = 0.38545758\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 995, loss = 0.38538911\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 996, loss = 0.38532392\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 997, loss = 0.38529689\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 998, loss = 0.38526762\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 999, loss = 0.38522126\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1000, loss = 0.38515463\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Scoring training: 0.8215434083601286\n",
      "Scoring test    : 0.8052434456928839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier # Multi-layer Perceptron\n",
    "from sklearn.metrics import log_loss # log-loss is based on how much the prediction varies from the actual label.\n",
    "\n",
    "N_iters = 1000\n",
    "architecture = (5,) # one single hidden layer with 5 neurons.\n",
    "\n",
    "X_tr1_sc, X_tr2_sc, y_tr1, y_tr2 = train_test_split(X_tr_sc, y_tr,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=1)\n",
    "\n",
    "# X_tr2, y_tr2 is the validation dataset to avoid overfitting in training.\n",
    "clf_nn = MLPClassifier(verbose=True, max_iter=1, random_state=7,\n",
    "                       hidden_layer_sizes=architecture,\n",
    "                       early_stopping=False, warm_start=True)\n",
    "# max_iter -> number of epochs (solver is 'adam')\n",
    "# early_stopping -> finish if validation score is not improving\n",
    "best_loss_in_val = 1e20\n",
    "for i in range(N_iters):\n",
    "    clf_nn.fit(X_tr1_sc, y_tr1)\n",
    "    loss_val = log_loss(y_tr2, clf_nn.predict_proba(X_tr2_sc))\n",
    "    if loss_val < best_loss_in_val:\n",
    "        best_weights = clf_nn.coefs_.copy()\n",
    "        best_loss_in_val = loss_val\n",
    "        print(\"nnet improvement in validation\")\n",
    "\n",
    "clf_nn.coefs_ = best_weights\n",
    "print(\"Scoring training:\", clf_nn.score(X_tr_sc, y_tr))\n",
    "print(\"Scoring test    :\", clf_nn.score(X_te_sc, y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Support Vector Machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses a hyperplane to separate the different classes. This hyperplane is the one that has the largest separation between the two classes.\n",
    "If the two classes are not linearly separable, it adds dimensions by operating with the existing ones (kernel function), so that in this new space the two classes were separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svm = SVC() # Support Vector Classification\n",
    "\n",
    "# We will probably have more training examples with Survived=0 than examples with Survived=1. That's why we use StratifiedKFold\n",
    "# because it will ensure that each set contains approximately the same percentage of samples of each target class as the \n",
    "# complete set\n",
    "kfolds=10\n",
    "cv = StratifiedKFold(n_splits = kfolds) \n",
    "\n",
    "params = {\n",
    "    # lower C values means increase the regularization strength (more simple models -->underfit),\n",
    "    # bigger C values means decrease the regularization strength (more complex models -->overfit)\n",
    "    \"C\" : [0.001, 0.01, 0.1, 1, 1.1, 10],\n",
    "    \"kernel\" : [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\" : [\"auto\", \"scale\"]}\n",
    "\n",
    "# n_jobs=-1 --> Uses all processors\n",
    "# return_train_score=True --> cv_results_ attribute includes training scores\n",
    "grid = GridSearchCV(clf_svm, params, cv = cv, verbose = 0, n_jobs = -1, return_train_score=True)\n",
    "grid = grid.fit(X_sc, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "clf_svm = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 0.74 (+/- 0.01)\n",
      "Accuracy Test: 0.73 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Train: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_train_score'].mean(), grid.cv_results_['std_train_score'].mean() * 2))\n",
    "print(\"Accuracy Test: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_test_score'].mean(), grid.cv_results_['std_test_score'].mean() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructs a large number of decision trees at training time and outputs the most frequent class (mode) for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "# We will probably have more training examples with Survived=0 than examples with Survived=1. That's why we use StratifiedKFold\n",
    "# because it will ensure that each set contains approximately the same percentage of samples of each target class as the \n",
    "# complete set\n",
    "kfolds=10\n",
    "cv = StratifiedKFold(n_splits = kfolds) \n",
    "\n",
    "params = {\n",
    "    # n_estimators --> number of trees in the forest\n",
    "    \"n_estimators\" : [200, 300, 400, 500, 1000],\n",
    "    # max_depth --> maximum depth of the tree\n",
    "    \"max_depth\" : [1, 3, 5, 7, 9]}\n",
    "\n",
    "# n_jobs=-1 --> Uses all processors\n",
    "# return_train_score=True --> cv_results_ attribute includes training scores\n",
    "grid = GridSearchCV(clf_rf, params, cv = cv, verbose = 0, n_jobs = -1, return_train_score=True)\n",
    "grid = grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "clf_rf = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 0.87 (+/- 0.01)\n",
      "Accuracy Test: 0.81 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Train: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_train_score'].mean(), grid.cv_results_['std_train_score'].mean() * 2))\n",
    "print(\"Accuracy Test: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_test_score'].mean(), grid.cv_results_['std_test_score'].mean() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines weak prediction models into a single strong learner. Unlike Random Forest (bagging) it gives more weight to misclassified examples (it's more likely that these examples appear in the next iteration's dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.005, 'max_depth': 5, 'max_features': 3, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gb = GradientBoostingClassifier()\n",
    "\n",
    "# We will probably have more training examples with Survived=0 than examples with Survived=1. That's why we use StratifiedKFold\n",
    "# because it will ensure that each set contains approximately the same percentage of samples of each target class as the \n",
    "# complete set\n",
    "kfolds=10\n",
    "cv = StratifiedKFold(n_splits = kfolds) \n",
    "\n",
    "params = {\n",
    "    \"n_estimators\" : [300, 500, 700],\n",
    "    \"learning_rate\" : [0.005, 0.01, 0.1],\n",
    "    \"max_depth\" : [3, 5], # maximum depth of the individual regression estimators\n",
    "    \"max_features\" : [3, 5]} # the number of features to consider when looking for the best split\n",
    "\n",
    "# n_jobs=-1 --> Uses all processors\n",
    "# return_train_score=True --> cv_results_ attribute includes training scores\n",
    "grid = GridSearchCV(clf_gb, params, cv = cv, verbose = 0, n_jobs = -1, return_train_score=True)\n",
    "grid = grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "clf_gb = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 0.92 (+/- 0.01)\n",
      "Accuracy Test: 0.82 (+/- 0.09)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.04118715, 0.03898272, 0.04031129, 0.03909768, 0.04354457,\n",
       "       0.03867994, 0.05106942, 0.04934192, 0.04110682, 0.05565813,\n",
       "       0.04679114, 0.04784286, 0.03723569, 0.03793899, 0.03865307,\n",
       "       0.04298892, 0.03834824, 0.03771461, 0.05045132, 0.04398026,\n",
       "       0.04051973, 0.04576558, 0.04691772, 0.05269645, 0.03968868,\n",
       "       0.04449943, 0.04281849, 0.03905288, 0.04895842, 0.04031562,\n",
       "       0.03997416, 0.04277232, 0.04203471, 0.03849509, 0.04514401,\n",
       "       0.04214142])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy Train: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_train_score'].mean(), grid.cv_results_['std_train_score'].mean() * 2))\n",
    "print(\"Accuracy Test: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_test_score'].mean(), grid.cv_results_['std_test_score'].mean() * 2))\n",
    "grid.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create models that predicts the value of a target variable by learning simple decision rules inferred from the data features. Usually they do not generalise the data well, but on the other hand they are simple to understand and to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'min_samples_leaf': 10, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "\n",
    "# We will probably have more training examples with Survived=0 than examples with Survived=1. That's why we use StratifiedKFold\n",
    "# because it will ensure that each set contains approximately the same percentage of samples of each target class as the \n",
    "# complete set\n",
    "kfolds=10\n",
    "cv = StratifiedKFold(n_splits = kfolds) \n",
    "\n",
    "#MIRAR QUE PARAMETROS PONER\n",
    "params = {\n",
    "    \"criterion\" : ['gini', 'entropy'], # function to measure the quality of a split\n",
    "    \"splitter\" : ['best', 'random'], # strategy used to choose the split at each node\n",
    "    \"min_samples_leaf\" : [1, 10, 20, 50]} # strategy used to choose the split at each node\n",
    "\n",
    "# n_jobs=-1 --> Uses all processors\n",
    "# return_train_score=True --> cv_results_ attribute includes training scores\n",
    "grid = GridSearchCV(clf_dt, params, cv = cv, verbose = 0, n_jobs = -1, return_train_score=True)\n",
    "grid = grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "clf_dt = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 0.87 (+/- 0.01)\n",
      "Accuracy Test: 0.79 (+/- 0.09)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.03470843, 0.05529441, 0.06010549, 0.04259565, 0.05426469,\n",
       "       0.02759692, 0.03084823, 0.05031868, 0.0564286 , 0.04022951,\n",
       "       0.05556268, 0.03817509, 0.05618975, 0.03232543, 0.03084823,\n",
       "       0.04716596])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy Train: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_train_score'].mean(), grid.cv_results_['std_train_score'].mean() * 2))\n",
    "print(\"Accuracy Test: %0.2f (+/- %0.2f)\" % (grid.cv_results_['mean_test_score'].mean(), grid.cv_results_['std_test_score'].mean() * 2))\n",
    "grid.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"3313pt\" height=\"1742pt\"\r\n",
       " viewBox=\"0.00 0.00 3313.00 1742.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1738)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1738 3309,-1738 3309,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1643,-1734 1511,-1734 1511,-1651 1643,-1651 1643,-1734\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1577\" y=\"-1718.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Sex_male &lt;= 0.112</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1577\" y=\"-1703.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.96</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1577\" y=\"-1688.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 889</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1577\" y=\"-1673.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [549, 340]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1577\" y=\"-1658.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1174,-1615 1028,-1615 1028,-1532 1174,-1532 1174,-1615\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1599.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pclass_Third &lt;= 0.668</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1584.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.826</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1569.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 312</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1554.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [81, 231]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1539.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1510.81,-1675.23C1425.41,-1654.24 1276.81,-1617.71 1183.95,-1594.89\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1184.58,-1591.44 1174.03,-1592.45 1182.91,-1598.24 1184.58,-1591.44\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1186.98\" y=\"-1610.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 38 -->\r\n",
       "<g id=\"node39\" class=\"node\"><title>38</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2174,-1615 2034,-1615 2034,-1532 2174,-1532 2174,-1615\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2104\" y=\"-1599.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pclass_First &lt;= 0.803</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2104\" y=\"-1584.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.699</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2104\" y=\"-1569.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 577</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2104\" y=\"-1554.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [468, 109]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2104\" y=\"-1539.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;38 -->\r\n",
       "<g id=\"edge38\" class=\"edge\"><title>0&#45;&gt;38</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1643.21,-1676.8C1740.02,-1655.31 1919.98,-1615.36 2024.04,-1592.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2024.87,-1595.65 2033.87,-1590.07 2023.35,-1588.82 2024.87,-1595.65\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2020.44\" y=\"-1607.46\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"455,-1496 311,-1496 311,-1413 455,-1413 455,-1496\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-1480.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Embarked_S &lt;= 0.647</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-1465.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.301</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-1450.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 168</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-1435.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [9, 159]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-1420.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1027.87,-1560.58C893.049,-1538.61 606.226,-1491.88 465.018,-1468.87\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"465.54,-1465.4 455.107,-1467.25 464.414,-1472.31 465.54,-1465.4\"/>\r\n",
       "</g>\r\n",
       "<!-- 19 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>19</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1173,-1496 1029,-1496 1029,-1413 1173,-1413 1173,-1496\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1480.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Embarked_S &lt;= 0.502</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1465.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 1.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1450.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 144</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1435.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [72, 72]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1420.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;19 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>1&#45;&gt;19</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1101,-1531.91C1101,-1523.65 1101,-1514.86 1101,-1506.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1104.5,-1506.02 1101,-1496.02 1097.5,-1506.02 1104.5,-1506.02\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"238,-1377 128,-1377 128,-1294 238,-1294 238,-1377\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1361.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Fare &lt;= 64.786</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1346.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.135</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1331.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 53</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1316.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 52]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1301.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M313.611,-1412.91C291.895,-1400.2 268.048,-1386.25 246.74,-1373.79\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"248.489,-1370.76 238.09,-1368.73 244.954,-1376.8 248.489,-1370.76\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"438,-1377 328,-1377 328,-1294 438,-1294 438,-1377\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-1361.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3 &lt;= &#45;0.807</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-1346.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.364</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-1331.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 115</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-1316.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [8, 107]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-1301.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M383,-1412.91C383,-1404.65 383,-1395.86 383,-1387.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"386.5,-1387.02 383,-1377.02 379.5,-1387.02 386.5,-1387.02\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-1250.5 0,-1250.5 0,-1182.5 110,-1182.5 110,-1250.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-1235.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.297</text>\r\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-1220.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 19</text>\r\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-1205.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 18]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-1190.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M138.591,-1293.91C125.674,-1282.1 111.579,-1269.22 98.7055,-1257.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"101.028,-1254.83 91.2852,-1250.67 96.3049,-1260 101.028,-1254.83\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"238,-1250.5 128,-1250.5 128,-1182.5 238,-1182.5 238,-1250.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1235.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1220.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 34</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1205.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 34]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1190.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M183,-1293.91C183,-1283.2 183,-1271.62 183,-1260.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"186.5,-1260.67 183,-1250.67 179.5,-1260.67 186.5,-1260.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"366,-1258 256,-1258 256,-1175 366,-1175 366,-1258\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-1242.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Age &lt;= 29.476</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-1227.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.619</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-1212.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 26</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-1197.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [4, 22]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>6&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M358.02,-1293.91C352.603,-1285.1 346.817,-1275.7 341.223,-1266.61\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"344.158,-1264.7 335.936,-1258.02 338.196,-1268.37 344.158,-1264.7\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"524,-1258 384,-1258 384,-1175 524,-1175 524,-1258\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"454\" y=\"-1242.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pclass_First &lt;= 0.649</text>\r\n",
       "<text text-anchor=\"middle\" x=\"454\" y=\"-1227.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.265</text>\r\n",
       "<text text-anchor=\"middle\" x=\"454\" y=\"-1212.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 89</text>\r\n",
       "<text text-anchor=\"middle\" x=\"454\" y=\"-1197.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [4, 85]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"454\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>6&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M407.633,-1293.91C412.975,-1285.1 418.68,-1275.7 424.197,-1266.61\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"427.215,-1268.39 429.41,-1258.02 421.23,-1264.75 427.215,-1268.39\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"238,-1131.5 128,-1131.5 128,-1063.5 238,-1063.5 238,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.75</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 14</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [3, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266.591,-1174.91C253.674,-1163.1 239.579,-1150.22 226.705,-1138.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"229.028,-1135.83 219.285,-1131.67 224.305,-1141 229.028,-1135.83\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"366,-1131.5 256,-1131.5 256,-1063.5 366,-1063.5 366,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.414</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>7&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M311,-1174.91C311,-1164.2 311,-1152.62 311,-1141.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"314.5,-1141.67 311,-1131.67 307.5,-1141.67 314.5,-1141.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"494,-1139 384,-1139 384,-1056 494,-1056 494,-1139\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-1123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2 &lt;= 0.922</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-1108.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.327</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-1093.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 50</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-1078.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [3, 47]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-1063.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>10&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M448.796,-1174.91C447.725,-1166.56 446.586,-1157.67 445.477,-1149.02\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"448.938,-1148.49 444.195,-1139.02 441.995,-1149.38 448.938,-1148.49\"/>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"622,-1139 512,-1139 512,-1056 622,-1056 622,-1139\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-1123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SibSp &lt;= 0.598</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-1108.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.172</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-1093.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 39</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-1078.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 38]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-1063.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;16 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>10&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M493.205,-1174.91C502.057,-1165.74 511.537,-1155.93 520.652,-1146.49\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"523.435,-1148.65 527.865,-1139.02 518.4,-1143.78 523.435,-1148.65\"/>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"366,-1020 256,-1020 256,-937 366,-937 366,-1020\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-1004.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SibSp &lt;= 0.339</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-989.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.176</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-974.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 38</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-959.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 37]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-944.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M394.591,-1055.91C384.365,-1046.56 373.4,-1036.54 362.888,-1026.93\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"365.073,-1024.18 355.33,-1020.02 360.35,-1029.35 365.073,-1024.18\"/>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"494,-1012.5 384,-1012.5 384,-944.5 494,-944.5 494,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.65</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [2, 10]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;15 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>11&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M439,-1055.91C439,-1045.2 439,-1033.62 439,-1022.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"442.5,-1022.67 439,-1012.67 435.5,-1022.67 442.5,-1022.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"302,-893.5 192,-893.5 192,-825.5 302,-825.5 302,-893.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-878.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.276</text>\r\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-863.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 21</text>\r\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-848.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 20]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-833.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>12&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M288.796,-936.907C282.76,-925.873 276.209,-913.898 270.124,-902.773\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"273.012,-900.76 265.143,-893.667 266.871,-904.12 273.012,-900.76\"/>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"430,-893.5 320,-893.5 320,-825.5 430,-825.5 430,-893.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-878.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-863.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 17</text>\r\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-848.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 17]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-833.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>12&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M333.204,-936.907C339.24,-925.873 345.791,-913.898 351.876,-902.773\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.129,-904.12 356.857,-893.667 348.988,-900.76 355.129,-904.12\"/>\r\n",
       "</g>\r\n",
       "<!-- 17 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>17</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"622,-1012.5 512,-1012.5 512,-944.5 622,-944.5 622,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 19</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 19]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 16&#45;&gt;17 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>16&#45;&gt;17</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M567,-1055.91C567,-1045.2 567,-1033.62 567,-1022.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"570.5,-1022.67 567,-1012.67 563.5,-1022.67 570.5,-1022.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 18 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"750,-1012.5 640,-1012.5 640,-944.5 750,-944.5 750,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.286</text>\r\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 20</text>\r\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 19]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 16&#45;&gt;18 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>16&#45;&gt;18</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.409,-1055.91C624.326,-1044.1 638.421,-1031.22 651.295,-1019.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"653.695,-1022 658.715,-1012.67 648.972,-1016.83 653.695,-1022\"/>\r\n",
       "</g>\r\n",
       "<!-- 20 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>20</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1086,-1377 976,-1377 976,-1294 1086,-1294 1086,-1377\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1031\" y=\"-1361.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Fare &lt;= 10.217</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1031\" y=\"-1346.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.886</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1031\" y=\"-1331.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 56</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1031\" y=\"-1316.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [17, 39]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1031\" y=\"-1301.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 19&#45;&gt;20 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>19&#45;&gt;20</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1076.71,-1412.91C1071.45,-1404.1 1065.82,-1394.7 1060.38,-1385.61\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1063.38,-1383.81 1055.24,-1377.02 1057.37,-1387.4 1063.38,-1383.81\"/>\r\n",
       "</g>\r\n",
       "<!-- 27 -->\r\n",
       "<g id=\"node28\" class=\"node\"><title>27</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1306,-1377 1174,-1377 1174,-1294 1306,-1294 1306,-1377\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1361.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Fare &lt;= 25.654</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1346.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.954</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1331.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 88</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1316.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [55, 33]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1301.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 19&#45;&gt;27 -->\r\n",
       "<g id=\"edge27\" class=\"edge\"><title>19&#45;&gt;27</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1149.23,-1412.91C1160.44,-1403.47 1172.47,-1393.34 1183.99,-1383.65\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1186.46,-1386.14 1191.86,-1377.02 1181.96,-1380.78 1186.46,-1386.14\"/>\r\n",
       "</g>\r\n",
       "<!-- 21 -->\r\n",
       "<g id=\"node22\" class=\"node\"><title>21</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"878,-1258 768,-1258 768,-1175 878,-1175 878,-1258\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-1242.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3 &lt;= 0.896</text>\r\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-1227.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.784</text>\r\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-1212.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 30</text>\r\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-1197.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [7, 23]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 20&#45;&gt;21 -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>20&#45;&gt;21</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M975.806,-1303.45C948.547,-1288.12 915.503,-1269.53 887.127,-1253.57\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"888.523,-1250.34 878.091,-1248.49 885.091,-1256.44 888.523,-1250.34\"/>\r\n",
       "</g>\r\n",
       "<!-- 24 -->\r\n",
       "<g id=\"node25\" class=\"node\"><title>24</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1086,-1258 976,-1258 976,-1175 1086,-1175 1086,-1258\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1031\" y=\"-1242.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SibSp &lt;= 0.285</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1031\" y=\"-1227.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.961</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1031\" y=\"-1212.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 26</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1031\" y=\"-1197.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [10, 16]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1031\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 20&#45;&gt;24 -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>20&#45;&gt;24</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1031,-1293.91C1031,-1285.65 1031,-1276.86 1031,-1268.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1034.5,-1268.02 1031,-1258.02 1027.5,-1268.02 1034.5,-1268.02\"/>\r\n",
       "</g>\r\n",
       "<!-- 22 -->\r\n",
       "<g id=\"node23\" class=\"node\"><title>22</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"750,-1131.5 640,-1131.5 640,-1063.5 750,-1063.5 750,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.503</text>\r\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 18</text>\r\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [2, 16]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"695\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 21&#45;&gt;22 -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>21&#45;&gt;22</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M778.591,-1174.91C765.674,-1163.1 751.579,-1150.22 738.705,-1138.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"741.028,-1135.83 731.285,-1131.67 736.305,-1141 741.028,-1135.83\"/>\r\n",
       "</g>\r\n",
       "<!-- 23 -->\r\n",
       "<g id=\"node24\" class=\"node\"><title>23</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"878,-1131.5 768,-1131.5 768,-1063.5 878,-1063.5 878,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.98</text>\r\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [5, 7]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"823\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 21&#45;&gt;23 -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>21&#45;&gt;23</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M823,-1174.91C823,-1164.2 823,-1152.62 823,-1141.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"826.5,-1141.67 823,-1131.67 819.5,-1141.67 826.5,-1141.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 25 -->\r\n",
       "<g id=\"node26\" class=\"node\"><title>25</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1028,-1131.5 896,-1131.5 896,-1063.5 1028,-1063.5 1028,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"962\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 1.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"962\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"962\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [5, 5]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"962\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 24&#45;&gt;25 -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>24&#45;&gt;25</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1007.06,-1174.91C1000.49,-1163.76 993.35,-1151.66 986.733,-1140.44\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"989.655,-1138.5 981.56,-1131.67 983.625,-1142.06 989.655,-1138.5\"/>\r\n",
       "</g>\r\n",
       "<!-- 26 -->\r\n",
       "<g id=\"node27\" class=\"node\"><title>26</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1156,-1131.5 1046,-1131.5 1046,-1063.5 1156,-1063.5 1156,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.896</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 16</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [5, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 24&#45;&gt;26 -->\r\n",
       "<g id=\"edge26\" class=\"edge\"><title>24&#45;&gt;26</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1055.29,-1174.91C1061.95,-1163.76 1069.2,-1151.66 1075.91,-1140.44\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.03,-1142.05 1081.16,-1131.67 1073.02,-1138.45 1079.03,-1142.05\"/>\r\n",
       "</g>\r\n",
       "<!-- 28 -->\r\n",
       "<g id=\"node29\" class=\"node\"><title>28</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1306,-1258 1174,-1258 1174,-1175 1306,-1175 1306,-1258\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1242.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SibSp &lt;= 0.947</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1227.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.993</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1212.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 69</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1197.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [38, 31]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 27&#45;&gt;28 -->\r\n",
       "<g id=\"edge28\" class=\"edge\"><title>27&#45;&gt;28</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1240,-1293.91C1240,-1285.65 1240,-1276.86 1240,-1268.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1243.5,-1268.02 1240,-1258.02 1236.5,-1268.02 1243.5,-1268.02\"/>\r\n",
       "</g>\r\n",
       "<!-- 37 -->\r\n",
       "<g id=\"node38\" class=\"node\"><title>37</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1456,-1250.5 1324,-1250.5 1324,-1182.5 1456,-1182.5 1456,-1250.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1390\" y=\"-1235.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.485</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1390\" y=\"-1220.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 19</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1390\" y=\"-1205.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [17, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1390\" y=\"-1190.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 27&#45;&gt;37 -->\r\n",
       "<g id=\"edge37\" class=\"edge\"><title>27&#45;&gt;37</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1292.04,-1293.91C1307.32,-1281.99 1324.01,-1268.98 1339.21,-1257.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1341.75,-1259.58 1347.48,-1250.67 1337.44,-1254.06 1341.75,-1259.58\"/>\r\n",
       "</g>\r\n",
       "<!-- 29 -->\r\n",
       "<g id=\"node30\" class=\"node\"><title>29</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1306,-1139 1174,-1139 1174,-1056 1306,-1056 1306,-1139\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2 &lt;= 0.739</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1108.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 1.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1093.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 40</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1078.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [20, 20]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-1063.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 28&#45;&gt;29 -->\r\n",
       "<g id=\"edge29\" class=\"edge\"><title>28&#45;&gt;29</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1240,-1174.91C1240,-1166.65 1240,-1157.86 1240,-1149.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1243.5,-1149.02 1240,-1139.02 1236.5,-1149.02 1243.5,-1149.02\"/>\r\n",
       "</g>\r\n",
       "<!-- 34 -->\r\n",
       "<g id=\"node35\" class=\"node\"><title>34</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1456,-1139 1324,-1139 1324,-1056 1456,-1056 1456,-1139\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1390\" y=\"-1123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2 &lt;= 0.372</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1390\" y=\"-1108.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.958</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1390\" y=\"-1093.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 29</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1390\" y=\"-1078.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [18, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1390\" y=\"-1063.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 28&#45;&gt;34 -->\r\n",
       "<g id=\"edge34\" class=\"edge\"><title>28&#45;&gt;34</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1292.04,-1174.91C1304.26,-1165.38 1317.37,-1155.15 1329.91,-1145.37\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1332.32,-1147.93 1338.05,-1139.02 1328.01,-1142.41 1332.32,-1147.93\"/>\r\n",
       "</g>\r\n",
       "<!-- 30 -->\r\n",
       "<g id=\"node31\" class=\"node\"><title>30</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1167,-1020 1035,-1020 1035,-937 1167,-937 1167,-1020\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-1004.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3 &lt;= 0.496</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-989.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.999</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-974.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 29</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-959.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [15, 14]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1101\" y=\"-944.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 29&#45;&gt;30 -->\r\n",
       "<g id=\"edge30\" class=\"edge\"><title>29&#45;&gt;30</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1191.77,-1055.91C1180.56,-1046.47 1168.53,-1036.34 1157.01,-1026.65\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1159.04,-1023.78 1149.14,-1020.02 1154.54,-1029.14 1159.04,-1023.78\"/>\r\n",
       "</g>\r\n",
       "<!-- 33 -->\r\n",
       "<g id=\"node34\" class=\"node\"><title>33</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1295,-1012.5 1185,-1012.5 1185,-944.5 1295,-944.5 1295,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.994</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 11</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [5, 6]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1240\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 29&#45;&gt;33 -->\r\n",
       "<g id=\"edge33\" class=\"edge\"><title>29&#45;&gt;33</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1240,-1055.91C1240,-1045.2 1240,-1033.62 1240,-1022.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1243.5,-1022.67 1240,-1012.67 1236.5,-1022.67 1243.5,-1022.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 31 -->\r\n",
       "<g id=\"node32\" class=\"node\"><title>31</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1092,-893.5 960,-893.5 960,-825.5 1092,-825.5 1092,-893.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1026\" y=\"-878.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.998</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1026\" y=\"-863.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 19</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1026\" y=\"-848.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [10, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1026\" y=\"-833.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 30&#45;&gt;31 -->\r\n",
       "<g id=\"edge31\" class=\"edge\"><title>30&#45;&gt;31</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1074.98,-936.907C1067.76,-925.652 1059.92,-913.418 1052.67,-902.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1055.6,-900.197 1047.26,-893.667 1049.71,-903.975 1055.6,-900.197\"/>\r\n",
       "</g>\r\n",
       "<!-- 32 -->\r\n",
       "<g id=\"node33\" class=\"node\"><title>32</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1242,-893.5 1110,-893.5 1110,-825.5 1242,-825.5 1242,-893.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1176\" y=\"-878.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 1.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1176\" y=\"-863.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1176\" y=\"-848.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [5, 5]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1176\" y=\"-833.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 30&#45;&gt;32 -->\r\n",
       "<g id=\"edge32\" class=\"edge\"><title>30&#45;&gt;32</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1127.02,-936.907C1134.24,-925.652 1142.08,-913.418 1149.33,-902.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1152.29,-903.975 1154.74,-893.667 1146.4,-900.197 1152.29,-903.975\"/>\r\n",
       "</g>\r\n",
       "<!-- 35 -->\r\n",
       "<g id=\"node36\" class=\"node\"><title>35</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1445,-1012.5 1313,-1012.5 1313,-944.5 1445,-944.5 1445,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1379\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.837</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1379\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 15</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1379\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [11, 4]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1379\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 34&#45;&gt;35 -->\r\n",
       "<g id=\"edge35\" class=\"edge\"><title>34&#45;&gt;35</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1386.18,-1055.91C1385.18,-1045.2 1384.09,-1033.62 1383.07,-1022.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1386.54,-1022.3 1382.12,-1012.67 1379.57,-1022.95 1386.54,-1022.3\"/>\r\n",
       "</g>\r\n",
       "<!-- 36 -->\r\n",
       "<g id=\"node37\" class=\"node\"><title>36</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1595,-1012.5 1463,-1012.5 1463,-944.5 1595,-944.5 1595,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1529\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 1.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1529\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 14</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1529\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [7, 7]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1529\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 34&#45;&gt;36 -->\r\n",
       "<g id=\"edge36\" class=\"edge\"><title>34&#45;&gt;36</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1438.23,-1055.91C1452.38,-1043.99 1467.85,-1030.98 1481.93,-1019.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1484.2,-1021.78 1489.6,-1012.67 1479.69,-1016.43 1484.2,-1021.78\"/>\r\n",
       "</g>\r\n",
       "<!-- 39 -->\r\n",
       "<g id=\"node40\" class=\"node\"><title>39</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2170,-1496 2038,-1496 2038,-1413 2170,-1413 2170,-1496\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2104\" y=\"-1480.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Parch &lt;= 0.104</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2104\" y=\"-1465.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.586</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2104\" y=\"-1450.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 455</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2104\" y=\"-1435.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [391, 64]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2104\" y=\"-1420.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 38&#45;&gt;39 -->\r\n",
       "<g id=\"edge39\" class=\"edge\"><title>38&#45;&gt;39</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2104,-1531.91C2104,-1523.65 2104,-1514.86 2104,-1506.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2107.5,-1506.02 2104,-1496.02 2100.5,-1506.02 2107.5,-1506.02\"/>\r\n",
       "</g>\r\n",
       "<!-- 92 -->\r\n",
       "<g id=\"node93\" class=\"node\"><title>92</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2819,-1496 2687,-1496 2687,-1413 2819,-1413 2819,-1496\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2753\" y=\"-1480.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Age &lt;= 42.082</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2753\" y=\"-1465.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.95</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2753\" y=\"-1450.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 122</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2753\" y=\"-1435.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [77, 45]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2753\" y=\"-1420.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 38&#45;&gt;92 -->\r\n",
       "<g id=\"edge92\" class=\"edge\"><title>38&#45;&gt;92</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2174.07,-1559.87C2296.77,-1537.75 2549.55,-1492.18 2676.58,-1469.28\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2677.4,-1472.68 2686.62,-1467.47 2676.16,-1465.8 2677.4,-1472.68\"/>\r\n",
       "</g>\r\n",
       "<!-- 40 -->\r\n",
       "<g id=\"node41\" class=\"node\"><title>40</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2092,-1377 1960,-1377 1960,-1294 2092,-1294 2092,-1377\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2026\" y=\"-1361.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Age &lt;= 20.494</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2026\" y=\"-1346.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.513</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2026\" y=\"-1331.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 385</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2026\" y=\"-1316.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [341, 44]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2026\" y=\"-1301.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 39&#45;&gt;40 -->\r\n",
       "<g id=\"edge40\" class=\"edge\"><title>39&#45;&gt;40</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2076.94,-1412.91C2071.07,-1404.1 2064.8,-1394.7 2058.74,-1385.61\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2061.47,-1383.4 2053.01,-1377.02 2055.65,-1387.28 2061.47,-1383.4\"/>\r\n",
       "</g>\r\n",
       "<!-- 85 -->\r\n",
       "<g id=\"node86\" class=\"node\"><title>85</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2256,-1377 2110,-1377 2110,-1294 2256,-1294 2256,-1377\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2183\" y=\"-1361.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pclass_Third &lt;= 0.353</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2183\" y=\"-1346.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.863</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2183\" y=\"-1331.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 70</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2183\" y=\"-1316.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [50, 20]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2183\" y=\"-1301.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 39&#45;&gt;85 -->\r\n",
       "<g id=\"edge85\" class=\"edge\"><title>39&#45;&gt;85</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2131.41,-1412.91C2137.41,-1404.01 2143.83,-1394.51 2150.03,-1385.33\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2152.94,-1387.27 2155.64,-1377.02 2147.14,-1383.35 2152.94,-1387.27\"/>\r\n",
       "</g>\r\n",
       "<!-- 41 -->\r\n",
       "<g id=\"node42\" class=\"node\"><title>41</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1946,-1258 1800,-1258 1800,-1175 1946,-1175 1946,-1258\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1873\" y=\"-1242.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Embarked_C &lt;= 0.839</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1873\" y=\"-1227.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.634</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1873\" y=\"-1212.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 75</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1873\" y=\"-1197.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [63, 12]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1873\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 40&#45;&gt;41 -->\r\n",
       "<g id=\"edge41\" class=\"edge\"><title>40&#45;&gt;41</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1972.92,-1293.91C1960.46,-1284.38 1947.08,-1274.15 1934.29,-1264.37\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1936.06,-1261.32 1925.99,-1258.02 1931.81,-1266.88 1936.06,-1261.32\"/>\r\n",
       "</g>\r\n",
       "<!-- 50 -->\r\n",
       "<g id=\"node51\" class=\"node\"><title>50</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2096,-1258 1964,-1258 1964,-1175 2096,-1175 2096,-1258\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2030\" y=\"-1242.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Fare &lt;= 48.115</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2030\" y=\"-1227.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.479</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2030\" y=\"-1212.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 310</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2030\" y=\"-1197.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [278, 32]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2030\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 40&#45;&gt;50 -->\r\n",
       "<g id=\"edge50\" class=\"edge\"><title>40&#45;&gt;50</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2027.39,-1293.91C2027.67,-1285.56 2027.98,-1276.67 2028.27,-1268.02\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2031.77,-1268.13 2028.61,-1258.02 2024.77,-1267.9 2031.77,-1268.13\"/>\r\n",
       "</g>\r\n",
       "<!-- 42 -->\r\n",
       "<g id=\"node43\" class=\"node\"><title>42</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1796,-1139 1664,-1139 1664,-1056 1796,-1056 1796,-1139\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1730\" y=\"-1123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Age &lt;= 17.242</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1730\" y=\"-1108.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.58</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1730\" y=\"-1093.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 65</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1730\" y=\"-1078.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [56, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1730\" y=\"-1063.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 41&#45;&gt;42 -->\r\n",
       "<g id=\"edge42\" class=\"edge\"><title>41&#45;&gt;42</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1823.39,-1174.91C1811.74,-1165.38 1799.24,-1155.15 1787.29,-1145.37\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1789.48,-1142.64 1779.53,-1139.02 1785.05,-1148.06 1789.48,-1142.64\"/>\r\n",
       "</g>\r\n",
       "<!-- 49 -->\r\n",
       "<g id=\"node50\" class=\"node\"><title>49</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1946,-1131.5 1814,-1131.5 1814,-1063.5 1946,-1063.5 1946,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1880\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.881</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1880\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1880\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [7, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1880\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 41&#45;&gt;49 -->\r\n",
       "<g id=\"edge49\" class=\"edge\"><title>41&#45;&gt;49</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1875.43,-1174.91C1876.07,-1164.2 1876.76,-1152.62 1877.41,-1141.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1880.91,-1141.86 1878.02,-1131.67 1873.92,-1141.44 1880.91,-1141.86\"/>\r\n",
       "</g>\r\n",
       "<!-- 43 -->\r\n",
       "<g id=\"node44\" class=\"node\"><title>43</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1745,-1020 1613,-1020 1613,-937 1745,-937 1745,-1020\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1679\" y=\"-1004.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2 &lt;= &#45;0.079</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1679\" y=\"-989.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.684</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1679\" y=\"-974.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 22</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1679\" y=\"-959.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [18, 4]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1679\" y=\"-944.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 42&#45;&gt;43 -->\r\n",
       "<g id=\"edge43\" class=\"edge\"><title>42&#45;&gt;43</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1712.31,-1055.91C1708.59,-1047.38 1704.62,-1038.28 1700.78,-1029.46\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1703.87,-1027.79 1696.66,-1020.02 1697.45,-1030.59 1703.87,-1027.79\"/>\r\n",
       "</g>\r\n",
       "<!-- 46 -->\r\n",
       "<g id=\"node47\" class=\"node\"><title>46</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1895,-1020 1763,-1020 1763,-937 1895,-937 1895,-1020\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1829\" y=\"-1004.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3 &lt;= 0.634</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1829\" y=\"-989.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.519</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1829\" y=\"-974.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 43</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1829\" y=\"-959.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [38, 5]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1829\" y=\"-944.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 42&#45;&gt;46 -->\r\n",
       "<g id=\"edge46\" class=\"edge\"><title>42&#45;&gt;46</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1764.35,-1055.91C1772.03,-1046.83 1780.24,-1037.12 1788.16,-1027.77\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1790.93,-1029.92 1794.71,-1020.02 1785.58,-1025.39 1790.93,-1029.92\"/>\r\n",
       "</g>\r\n",
       "<!-- 44 -->\r\n",
       "<g id=\"node45\" class=\"node\"><title>44</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1595,-893.5 1463,-893.5 1463,-825.5 1595,-825.5 1595,-893.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1529\" y=\"-878.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.811</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1529\" y=\"-863.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1529\" y=\"-848.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [9, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1529\" y=\"-833.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 43&#45;&gt;44 -->\r\n",
       "<g id=\"edge44\" class=\"edge\"><title>43&#45;&gt;44</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1626.96,-936.907C1611.68,-924.99 1594.99,-911.976 1579.79,-900.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1581.56,-897.058 1571.52,-893.667 1577.25,-902.577 1581.56,-897.058\"/>\r\n",
       "</g>\r\n",
       "<!-- 45 -->\r\n",
       "<g id=\"node46\" class=\"node\"><title>45</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1745,-893.5 1613,-893.5 1613,-825.5 1745,-825.5 1745,-893.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1679\" y=\"-878.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.469</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1679\" y=\"-863.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1679\" y=\"-848.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [9, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1679\" y=\"-833.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 43&#45;&gt;45 -->\r\n",
       "<g id=\"edge45\" class=\"edge\"><title>43&#45;&gt;45</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1679,-936.907C1679,-926.204 1679,-914.615 1679,-903.776\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1682.5,-903.667 1679,-893.667 1675.5,-903.667 1682.5,-903.667\"/>\r\n",
       "</g>\r\n",
       "<!-- 47 -->\r\n",
       "<g id=\"node48\" class=\"node\"><title>47</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1895,-893.5 1763,-893.5 1763,-825.5 1895,-825.5 1895,-893.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1829\" y=\"-878.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.439</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1829\" y=\"-863.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 33</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1829\" y=\"-848.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [30, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1829\" y=\"-833.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 46&#45;&gt;47 -->\r\n",
       "<g id=\"edge47\" class=\"edge\"><title>46&#45;&gt;47</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1829,-936.907C1829,-926.204 1829,-914.615 1829,-903.776\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1832.5,-903.667 1829,-893.667 1825.5,-903.667 1832.5,-903.667\"/>\r\n",
       "</g>\r\n",
       "<!-- 48 -->\r\n",
       "<g id=\"node49\" class=\"node\"><title>48</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2045,-893.5 1913,-893.5 1913,-825.5 2045,-825.5 2045,-893.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1979\" y=\"-878.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.722</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1979\" y=\"-863.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1979\" y=\"-848.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [8, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1979\" y=\"-833.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 46&#45;&gt;48 -->\r\n",
       "<g id=\"edge48\" class=\"edge\"><title>46&#45;&gt;48</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1881.04,-936.907C1896.32,-924.99 1913.01,-911.976 1928.21,-900.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1930.75,-902.577 1936.48,-893.667 1926.44,-897.058 1930.75,-902.577\"/>\r\n",
       "</g>\r\n",
       "<!-- 51 -->\r\n",
       "<g id=\"node52\" class=\"node\"><title>51</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2096,-1139 1964,-1139 1964,-1056 2096,-1056 2096,-1139\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2030\" y=\"-1123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1 &lt;= &#45;1.57</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2030\" y=\"-1108.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.447</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2030\" y=\"-1093.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 300</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2030\" y=\"-1078.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [272, 28]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2030\" y=\"-1063.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 50&#45;&gt;51 -->\r\n",
       "<g id=\"edge51\" class=\"edge\"><title>50&#45;&gt;51</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2030,-1174.91C2030,-1166.65 2030,-1157.86 2030,-1149.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2033.5,-1149.02 2030,-1139.02 2026.5,-1149.02 2033.5,-1149.02\"/>\r\n",
       "</g>\r\n",
       "<!-- 84 -->\r\n",
       "<g id=\"node85\" class=\"node\"><title>84</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2246,-1131.5 2114,-1131.5 2114,-1063.5 2246,-1063.5 2246,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2180\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.971</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2180\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2180\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [6, 4]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2180\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 50&#45;&gt;84 -->\r\n",
       "<g id=\"edge84\" class=\"edge\"><title>50&#45;&gt;84</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2082.04,-1174.91C2097.32,-1162.99 2114.01,-1149.98 2129.21,-1138.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2131.75,-1140.58 2137.48,-1131.67 2127.44,-1135.06 2131.75,-1140.58\"/>\r\n",
       "</g>\r\n",
       "<!-- 52 -->\r\n",
       "<g id=\"node53\" class=\"node\"><title>52</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2045,-1012.5 1913,-1012.5 1913,-944.5 2045,-944.5 2045,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1979\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1979\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 14</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1979\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [14, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1979\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 51&#45;&gt;52 -->\r\n",
       "<g id=\"edge52\" class=\"edge\"><title>51&#45;&gt;52</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2012.31,-1055.91C2007.54,-1044.98 2002.38,-1033.14 1997.57,-1022.11\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2000.66,-1020.44 1993.46,-1012.67 1994.24,-1023.23 2000.66,-1020.44\"/>\r\n",
       "</g>\r\n",
       "<!-- 53 -->\r\n",
       "<g id=\"node54\" class=\"node\"><title>53</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2195,-1020 2063,-1020 2063,-937 2195,-937 2195,-1020\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2129\" y=\"-1004.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2 &lt;= &#45;1.498</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2129\" y=\"-989.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.462</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2129\" y=\"-974.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 286</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2129\" y=\"-959.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [258, 28]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2129\" y=\"-944.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 51&#45;&gt;53 -->\r\n",
       "<g id=\"edge53\" class=\"edge\"><title>51&#45;&gt;53</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2064.35,-1055.91C2072.03,-1046.83 2080.24,-1037.12 2088.16,-1027.77\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2090.93,-1029.92 2094.71,-1020.02 2085.58,-1025.39 2090.93,-1029.92\"/>\r\n",
       "</g>\r\n",
       "<!-- 54 -->\r\n",
       "<g id=\"node55\" class=\"node\"><title>54</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2195,-893.5 2063,-893.5 2063,-825.5 2195,-825.5 2195,-893.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2129\" y=\"-878.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2129\" y=\"-863.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 27</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2129\" y=\"-848.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [27, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2129\" y=\"-833.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 53&#45;&gt;54 -->\r\n",
       "<g id=\"edge54\" class=\"edge\"><title>53&#45;&gt;54</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2129,-936.907C2129,-926.204 2129,-914.615 2129,-903.776\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2132.5,-903.667 2129,-893.667 2125.5,-903.667 2132.5,-903.667\"/>\r\n",
       "</g>\r\n",
       "<!-- 55 -->\r\n",
       "<g id=\"node56\" class=\"node\"><title>55</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2345,-901 2213,-901 2213,-818 2345,-818 2345,-901\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2279\" y=\"-885.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3 &lt;= 1.188</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2279\" y=\"-870.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.494</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2279\" y=\"-855.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 259</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2279\" y=\"-840.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [231, 28]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2279\" y=\"-825.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 53&#45;&gt;55 -->\r\n",
       "<g id=\"edge55\" class=\"edge\"><title>53&#45;&gt;55</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2181.04,-936.907C2193.26,-927.379 2206.37,-917.148 2218.91,-907.37\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2221.32,-909.931 2227.05,-901.021 2217.01,-904.411 2221.32,-909.931\"/>\r\n",
       "</g>\r\n",
       "<!-- 56 -->\r\n",
       "<g id=\"node57\" class=\"node\"><title>56</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2270,-782 2138,-782 2138,-699 2270,-699 2270,-782\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2204\" y=\"-766.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3 &lt;= 0.219</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2204\" y=\"-751.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.517</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2204\" y=\"-736.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 233</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2204\" y=\"-721.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [206, 27]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2204\" y=\"-706.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 55&#45;&gt;56 -->\r\n",
       "<g id=\"edge56\" class=\"edge\"><title>55&#45;&gt;56</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2252.98,-817.907C2247.34,-809.105 2241.31,-799.703 2235.48,-790.612\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2238.32,-788.551 2229.97,-782.021 2232.43,-792.328 2238.32,-788.551\"/>\r\n",
       "</g>\r\n",
       "<!-- 83 -->\r\n",
       "<g id=\"node84\" class=\"node\"><title>83</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2420,-774.5 2288,-774.5 2288,-706.5 2420,-706.5 2420,-774.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2354\" y=\"-759.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.235</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2354\" y=\"-744.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 26</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2354\" y=\"-729.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [25, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2354\" y=\"-714.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 55&#45;&gt;83 -->\r\n",
       "<g id=\"edge83\" class=\"edge\"><title>55&#45;&gt;83</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2305.02,-817.907C2312.24,-806.652 2320.08,-794.418 2327.33,-783.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2330.29,-784.975 2332.74,-774.667 2324.4,-781.197 2330.29,-784.975\"/>\r\n",
       "</g>\r\n",
       "<!-- 57 -->\r\n",
       "<g id=\"node58\" class=\"node\"><title>57</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2199,-663 2053,-663 2053,-580 2199,-580 2199,-663\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-647.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Embarked_C &lt;= 0.948</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-632.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.397</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-617.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 140</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-602.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [129, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-587.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 56&#45;&gt;57 -->\r\n",
       "<g id=\"edge57\" class=\"edge\"><title>56&#45;&gt;57</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2176.94,-698.907C2171.07,-690.105 2164.8,-680.703 2158.74,-671.612\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2161.47,-669.4 2153.01,-663.021 2155.65,-673.283 2161.47,-669.4\"/>\r\n",
       "</g>\r\n",
       "<!-- 72 -->\r\n",
       "<g id=\"node73\" class=\"node\"><title>72</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2349,-663 2217,-663 2217,-580 2349,-580 2349,-663\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-647.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Age &lt;= 33.29</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-632.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.662</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-617.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 93</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-602.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [77, 16]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-587.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 56&#45;&gt;72 -->\r\n",
       "<g id=\"edge72\" class=\"edge\"><title>56&#45;&gt;72</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2231.41,-698.907C2237.41,-690.014 2243.83,-680.509 2250.03,-671.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2252.94,-673.267 2255.64,-663.021 2247.14,-669.35 2252.94,-673.267\"/>\r\n",
       "</g>\r\n",
       "<!-- 58 -->\r\n",
       "<g id=\"node59\" class=\"node\"><title>58</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2042,-544 1910,-544 1910,-461 2042,-461 2042,-544\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1976\" y=\"-528.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1 &lt;= &#45;0.794</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1976\" y=\"-513.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.355</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1976\" y=\"-498.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 119</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1976\" y=\"-483.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [111, 8]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1976\" y=\"-468.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 57&#45;&gt;58 -->\r\n",
       "<g id=\"edge58\" class=\"edge\"><title>57&#45;&gt;58</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2073.96,-579.907C2061.74,-570.379 2048.63,-560.148 2036.09,-550.37\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2037.99,-547.411 2027.95,-544.021 2033.68,-552.931 2037.99,-547.411\"/>\r\n",
       "</g>\r\n",
       "<!-- 71 -->\r\n",
       "<g id=\"node72\" class=\"node\"><title>71</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2192,-536.5 2060,-536.5 2060,-468.5 2192,-468.5 2192,-536.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-521.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.592</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-506.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 21</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-491.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [18, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-476.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 57&#45;&gt;71 -->\r\n",
       "<g id=\"edge71\" class=\"edge\"><title>57&#45;&gt;71</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2126,-579.907C2126,-569.204 2126,-557.615 2126,-546.776\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2129.5,-546.667 2126,-536.667 2122.5,-546.667 2129.5,-546.667\"/>\r\n",
       "</g>\r\n",
       "<!-- 59 -->\r\n",
       "<g id=\"node60\" class=\"node\"><title>59</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1892,-417.5 1760,-417.5 1760,-349.5 1892,-349.5 1892,-417.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1826\" y=\"-402.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1826\" y=\"-387.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1826\" y=\"-372.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [12, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1826\" y=\"-357.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 58&#45;&gt;59 -->\r\n",
       "<g id=\"edge59\" class=\"edge\"><title>58&#45;&gt;59</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1923.96,-460.907C1908.68,-448.99 1891.99,-435.976 1876.79,-424.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1878.56,-421.058 1868.52,-417.667 1874.25,-426.577 1878.56,-421.058\"/>\r\n",
       "</g>\r\n",
       "<!-- 60 -->\r\n",
       "<g id=\"node61\" class=\"node\"><title>60</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2042,-425 1910,-425 1910,-342 2042,-342 2042,-425\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1976\" y=\"-409.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2 &lt;= 0.381</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1976\" y=\"-394.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.383</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1976\" y=\"-379.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 107</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1976\" y=\"-364.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [99, 8]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1976\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 58&#45;&gt;60 -->\r\n",
       "<g id=\"edge60\" class=\"edge\"><title>58&#45;&gt;60</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1976,-460.907C1976,-452.649 1976,-443.864 1976,-435.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1979.5,-435.021 1976,-425.021 1972.5,-435.021 1979.5,-435.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 61 -->\r\n",
       "<g id=\"node62\" class=\"node\"><title>61</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1919,-306 1787,-306 1787,-223 1919,-223 1919,-306\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1853\" y=\"-290.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3 &lt;= &#45;1.168</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1853\" y=\"-275.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.301</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1853\" y=\"-260.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 56</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1853\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [53, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1853\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 60&#45;&gt;61 -->\r\n",
       "<g id=\"edge61\" class=\"edge\"><title>60&#45;&gt;61</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1933.33,-341.907C1923.5,-332.56 1912.96,-322.538 1902.86,-312.929\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1905.26,-310.377 1895.6,-306.021 1900.43,-315.449 1905.26,-310.377\"/>\r\n",
       "</g>\r\n",
       "<!-- 66 -->\r\n",
       "<g id=\"node67\" class=\"node\"><title>66</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2088.5,-306 1937.5,-306 1937.5,-223 2088.5,-223 2088.5,-306\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2013\" y=\"-290.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pclass_Second &lt;= 0.41</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2013\" y=\"-275.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.463</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2013\" y=\"-260.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 51</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2013\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [46, 5]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2013\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 60&#45;&gt;66 -->\r\n",
       "<g id=\"edge66\" class=\"edge\"><title>60&#45;&gt;66</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1988.84,-341.907C1991.51,-333.468 1994.35,-324.477 1997.11,-315.738\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2000.51,-316.611 2000.19,-306.021 1993.83,-314.5 2000.51,-316.611\"/>\r\n",
       "</g>\r\n",
       "<!-- 62 -->\r\n",
       "<g id=\"node63\" class=\"node\"><title>62</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1771,-179.5 1639,-179.5 1639,-111.5 1771,-111.5 1771,-179.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1705\" y=\"-164.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.439</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1705\" y=\"-149.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 11</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1705\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [10, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1705\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 61&#45;&gt;62 -->\r\n",
       "<g id=\"edge62\" class=\"edge\"><title>61&#45;&gt;62</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1801.65,-222.907C1786.58,-210.99 1770.11,-197.976 1755.12,-186.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1756.97,-183.123 1746.95,-179.667 1752.63,-188.614 1756.97,-183.123\"/>\r\n",
       "</g>\r\n",
       "<!-- 63 -->\r\n",
       "<g id=\"node64\" class=\"node\"><title>63</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1921,-187 1789,-187 1789,-104 1921,-104 1921,-187\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1855\" y=\"-171.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1 &lt;= &#45;0.076</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1855\" y=\"-156.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.262</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1855\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 45</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1855\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [43, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1855\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 61&#45;&gt;63 -->\r\n",
       "<g id=\"edge63\" class=\"edge\"><title>61&#45;&gt;63</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1853.69,-222.907C1853.84,-214.558 1853.99,-205.671 1854.14,-197.02\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1857.64,-197.079 1854.31,-187.021 1850.64,-196.959 1857.64,-197.079\"/>\r\n",
       "</g>\r\n",
       "<!-- 64 -->\r\n",
       "<g id=\"node65\" class=\"node\"><title>64</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1772,-68 1640,-68 1640,-0 1772,-0 1772,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1706\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.337</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1706\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 16</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1706\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [15, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1706\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 63&#45;&gt;64 -->\r\n",
       "<g id=\"edge64\" class=\"edge\"><title>63&#45;&gt;64</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1799.52,-103.726C1786.49,-94.1494 1772.62,-83.9611 1759.67,-74.4438\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1761.44,-71.4012 1751.31,-68.2996 1757.3,-77.0418 1761.44,-71.4012\"/>\r\n",
       "</g>\r\n",
       "<!-- 65 -->\r\n",
       "<g id=\"node66\" class=\"node\"><title>65</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1922,-68 1790,-68 1790,-0 1922,-0 1922,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1856\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.216</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1856\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 29</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1856\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [28, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1856\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 63&#45;&gt;65 -->\r\n",
       "<g id=\"edge65\" class=\"edge\"><title>63&#45;&gt;65</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1855.37,-103.726C1855.45,-95.5175 1855.53,-86.8595 1855.6,-78.56\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1859.1,-78.3312 1855.7,-68.2996 1852.1,-78.2672 1859.1,-78.3312\"/>\r\n",
       "</g>\r\n",
       "<!-- 67 -->\r\n",
       "<g id=\"node68\" class=\"node\"><title>67</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2074,-187 1942,-187 1942,-104 2074,-104 2074,-187\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2008\" y=\"-171.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2 &lt;= 0.743</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2008\" y=\"-156.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.485</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2008\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 38</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2008\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [34, 4]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2008\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 66&#45;&gt;67 -->\r\n",
       "<g id=\"edge67\" class=\"edge\"><title>66&#45;&gt;67</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2011.27,-222.907C2010.91,-214.558 2010.53,-205.671 2010.16,-197.02\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2013.66,-196.862 2009.73,-187.021 2006.66,-197.161 2013.66,-196.862\"/>\r\n",
       "</g>\r\n",
       "<!-- 70 -->\r\n",
       "<g id=\"node71\" class=\"node\"><title>70</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2224,-179.5 2092,-179.5 2092,-111.5 2224,-111.5 2224,-179.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2158\" y=\"-164.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.391</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2158\" y=\"-149.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 13</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2158\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [12, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2158\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 66&#45;&gt;70 -->\r\n",
       "<g id=\"edge70\" class=\"edge\"><title>66&#45;&gt;70</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2063.31,-222.907C2078.08,-210.99 2094.21,-197.976 2108.9,-186.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2111.31,-188.67 2116.9,-179.667 2106.92,-183.223 2111.31,-188.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 68 -->\r\n",
       "<g id=\"node69\" class=\"node\"><title>68</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2073,-68 1941,-68 1941,-0 2073,-0 2073,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2007\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.414</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2007\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2007\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [11, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2007\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 67&#45;&gt;68 -->\r\n",
       "<g id=\"edge68\" class=\"edge\"><title>67&#45;&gt;68</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2007.63,-103.726C2007.55,-95.5175 2007.47,-86.8595 2007.4,-78.56\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2010.9,-78.2672 2007.3,-68.2996 2003.9,-78.3312 2010.9,-78.2672\"/>\r\n",
       "</g>\r\n",
       "<!-- 69 -->\r\n",
       "<g id=\"node70\" class=\"node\"><title>69</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2223,-68 2091,-68 2091,-0 2223,-0 2223,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2157\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.516</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2157\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 26</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2157\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [23, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2157\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 67&#45;&gt;69 -->\r\n",
       "<g id=\"edge69\" class=\"edge\"><title>67&#45;&gt;69</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2063.48,-103.726C2076.51,-94.1494 2090.38,-83.9611 2103.33,-74.4438\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2105.7,-77.0418 2111.69,-68.2996 2101.56,-71.4012 2105.7,-77.0418\"/>\r\n",
       "</g>\r\n",
       "<!-- 73 -->\r\n",
       "<g id=\"node74\" class=\"node\"><title>73</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2349,-544 2217,-544 2217,-461 2349,-461 2349,-544\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-528.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3 &lt;= 0.375</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-513.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.729</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-498.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 59</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-483.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [47, 12]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-468.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 72&#45;&gt;73 -->\r\n",
       "<g id=\"edge73\" class=\"edge\"><title>72&#45;&gt;73</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2283,-579.907C2283,-571.649 2283,-562.864 2283,-554.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2286.5,-554.021 2283,-544.021 2279.5,-554.021 2286.5,-554.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 80 -->\r\n",
       "<g id=\"node81\" class=\"node\"><title>80</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2506,-544 2374,-544 2374,-461 2506,-461 2506,-544\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2440\" y=\"-528.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3 &lt;= 0.805</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2440\" y=\"-513.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.523</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2440\" y=\"-498.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 34</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2440\" y=\"-483.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [30, 4]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2440\" y=\"-468.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 72&#45;&gt;80 -->\r\n",
       "<g id=\"edge80\" class=\"edge\"><title>72&#45;&gt;80</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2337.47,-579.907C2350.38,-570.288 2364.25,-559.953 2377.48,-550.09\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2379.7,-552.803 2385.63,-544.021 2375.52,-547.19 2379.7,-552.803\"/>\r\n",
       "</g>\r\n",
       "<!-- 74 -->\r\n",
       "<g id=\"node75\" class=\"node\"><title>74</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2192,-417.5 2060,-417.5 2060,-349.5 2192,-349.5 2192,-417.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-402.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-387.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-372.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [12, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2126\" y=\"-357.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 73&#45;&gt;74 -->\r\n",
       "<g id=\"edge74\" class=\"edge\"><title>73&#45;&gt;74</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2228.53,-460.907C2212.39,-448.88 2194.75,-435.735 2178.72,-423.791\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2180.62,-420.836 2170.51,-417.667 2176.43,-426.449 2180.62,-420.836\"/>\r\n",
       "</g>\r\n",
       "<!-- 75 -->\r\n",
       "<g id=\"node76\" class=\"node\"><title>75</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2356,-425 2210,-425 2210,-342 2356,-342 2356,-425\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-409.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pclass_Third &lt;= 0.966</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-394.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.82</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-379.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 47</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-364.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [35, 12]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2283\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 73&#45;&gt;75 -->\r\n",
       "<g id=\"edge75\" class=\"edge\"><title>73&#45;&gt;75</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2283,-460.907C2283,-452.649 2283,-443.864 2283,-435.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2286.5,-435.021 2283,-425.021 2279.5,-435.021 2286.5,-435.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 76 -->\r\n",
       "<g id=\"node77\" class=\"node\"><title>76</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2276,-298.5 2144,-298.5 2144,-230.5 2276,-230.5 2276,-298.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2210\" y=\"-283.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.439</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2210\" y=\"-268.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 11</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2210\" y=\"-253.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [10, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2210\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 75&#45;&gt;76 -->\r\n",
       "<g id=\"edge76\" class=\"edge\"><title>75&#45;&gt;76</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2257.67,-341.907C2250.72,-330.763 2243.17,-318.658 2236.17,-307.439\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2238.96,-305.298 2230.69,-298.667 2233.02,-309.004 2238.96,-305.298\"/>\r\n",
       "</g>\r\n",
       "<!-- 77 -->\r\n",
       "<g id=\"node78\" class=\"node\"><title>77</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2426,-306 2294,-306 2294,-223 2426,-223 2426,-306\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2360\" y=\"-290.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Age &lt;= 26.572</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2360\" y=\"-275.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.888</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2360\" y=\"-260.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 36</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2360\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [25, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2360\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 75&#45;&gt;77 -->\r\n",
       "<g id=\"edge77\" class=\"edge\"><title>75&#45;&gt;77</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2309.71,-341.907C2315.51,-333.105 2321.7,-323.703 2327.68,-314.612\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2330.76,-316.298 2333.33,-306.021 2324.91,-312.45 2330.76,-316.298\"/>\r\n",
       "</g>\r\n",
       "<!-- 78 -->\r\n",
       "<g id=\"node79\" class=\"node\"><title>78</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2400,-179.5 2268,-179.5 2268,-111.5 2400,-111.5 2400,-179.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2334\" y=\"-164.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.75</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2334\" y=\"-149.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 14</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2334\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [11, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2334\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 77&#45;&gt;78 -->\r\n",
       "<g id=\"edge78\" class=\"edge\"><title>77&#45;&gt;78</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2350.98,-222.907C2348.58,-212.094 2345.97,-200.376 2343.54,-189.441\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2346.96,-188.67 2341.37,-179.667 2340.12,-190.188 2346.96,-188.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 79 -->\r\n",
       "<g id=\"node80\" class=\"node\"><title>79</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2550,-179.5 2418,-179.5 2418,-111.5 2550,-111.5 2550,-179.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2484\" y=\"-164.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.946</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2484\" y=\"-149.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 22</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2484\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [14, 8]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2484\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 77&#45;&gt;79 -->\r\n",
       "<g id=\"edge79\" class=\"edge\"><title>77&#45;&gt;79</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2403.02,-222.907C2415.42,-211.211 2428.93,-198.457 2441.31,-186.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2443.98,-189.075 2448.85,-179.667 2439.17,-183.984 2443.98,-189.075\"/>\r\n",
       "</g>\r\n",
       "<!-- 81 -->\r\n",
       "<g id=\"node82\" class=\"node\"><title>81</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2506,-417.5 2374,-417.5 2374,-349.5 2506,-349.5 2506,-417.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2440\" y=\"-402.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.684</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2440\" y=\"-387.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 22</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2440\" y=\"-372.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [18, 4]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2440\" y=\"-357.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 80&#45;&gt;81 -->\r\n",
       "<g id=\"edge81\" class=\"edge\"><title>80&#45;&gt;81</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2440,-460.907C2440,-450.204 2440,-438.615 2440,-427.776\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2443.5,-427.667 2440,-417.667 2436.5,-427.667 2443.5,-427.667\"/>\r\n",
       "</g>\r\n",
       "<!-- 82 -->\r\n",
       "<g id=\"node83\" class=\"node\"><title>82</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2656,-417.5 2524,-417.5 2524,-349.5 2656,-349.5 2656,-417.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2590\" y=\"-402.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2590\" y=\"-387.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2590\" y=\"-372.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [12, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2590\" y=\"-357.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 80&#45;&gt;82 -->\r\n",
       "<g id=\"edge82\" class=\"edge\"><title>80&#45;&gt;82</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2492.04,-460.907C2507.32,-448.99 2524.01,-435.976 2539.21,-424.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2541.75,-426.577 2547.48,-417.667 2537.44,-421.058 2541.75,-426.577\"/>\r\n",
       "</g>\r\n",
       "<!-- 86 -->\r\n",
       "<g id=\"node87\" class=\"node\"><title>86</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2246,-1250.5 2114,-1250.5 2114,-1182.5 2246,-1182.5 2246,-1250.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2180\" y=\"-1235.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.998</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2180\" y=\"-1220.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 19</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2180\" y=\"-1205.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [10, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2180\" y=\"-1190.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 85&#45;&gt;86 -->\r\n",
       "<g id=\"edge86\" class=\"edge\"><title>85&#45;&gt;86</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2181.96,-1293.91C2181.68,-1283.2 2181.39,-1271.62 2181.11,-1260.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2184.61,-1260.57 2180.85,-1250.67 2177.61,-1260.75 2184.61,-1260.57\"/>\r\n",
       "</g>\r\n",
       "<!-- 87 -->\r\n",
       "<g id=\"node88\" class=\"node\"><title>87</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2396,-1258 2264,-1258 2264,-1175 2396,-1175 2396,-1258\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2330\" y=\"-1242.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SibSp &lt;= 3.667</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2330\" y=\"-1227.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.752</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2330\" y=\"-1212.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 51</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2330\" y=\"-1197.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [40, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2330\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 85&#45;&gt;87 -->\r\n",
       "<g id=\"edge87\" class=\"edge\"><title>85&#45;&gt;87</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2234,-1293.91C2245.97,-1284.38 2258.83,-1274.15 2271.11,-1264.37\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2273.44,-1266.99 2279.09,-1258.02 2269.09,-1261.51 2273.44,-1266.99\"/>\r\n",
       "</g>\r\n",
       "<!-- 88 -->\r\n",
       "<g id=\"node89\" class=\"node\"><title>88</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2396,-1139 2264,-1139 2264,-1056 2396,-1056 2396,-1139\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2330\" y=\"-1123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2 &lt;= 0.298</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2330\" y=\"-1108.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.907</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2330\" y=\"-1093.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 31</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2330\" y=\"-1078.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [21, 10]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2330\" y=\"-1063.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 87&#45;&gt;88 -->\r\n",
       "<g id=\"edge88\" class=\"edge\"><title>87&#45;&gt;88</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2330,-1174.91C2330,-1166.65 2330,-1157.86 2330,-1149.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2333.5,-1149.02 2330,-1139.02 2326.5,-1149.02 2333.5,-1149.02\"/>\r\n",
       "</g>\r\n",
       "<!-- 91 -->\r\n",
       "<g id=\"node92\" class=\"node\"><title>91</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2546,-1131.5 2414,-1131.5 2414,-1063.5 2546,-1063.5 2546,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2480\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.286</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2480\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 20</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2480\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [19, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2480\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 87&#45;&gt;91 -->\r\n",
       "<g id=\"edge91\" class=\"edge\"><title>87&#45;&gt;91</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2382.04,-1174.91C2397.32,-1162.99 2414.01,-1149.98 2429.21,-1138.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2431.75,-1140.58 2437.48,-1131.67 2427.44,-1135.06 2431.75,-1140.58\"/>\r\n",
       "</g>\r\n",
       "<!-- 89 -->\r\n",
       "<g id=\"node90\" class=\"node\"><title>89</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2345,-1012.5 2213,-1012.5 2213,-944.5 2345,-944.5 2345,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2279\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.9</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2279\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 19</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2279\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [13, 6]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2279\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 88&#45;&gt;89 -->\r\n",
       "<g id=\"edge89\" class=\"edge\"><title>88&#45;&gt;89</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2312.31,-1055.91C2307.54,-1044.98 2302.38,-1033.14 2297.57,-1022.11\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2300.66,-1020.44 2293.46,-1012.67 2294.24,-1023.23 2300.66,-1020.44\"/>\r\n",
       "</g>\r\n",
       "<!-- 90 -->\r\n",
       "<g id=\"node91\" class=\"node\"><title>90</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2495,-1012.5 2363,-1012.5 2363,-944.5 2495,-944.5 2495,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2429\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.918</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2429\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2429\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [8, 4]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2429\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 88&#45;&gt;90 -->\r\n",
       "<g id=\"edge90\" class=\"edge\"><title>88&#45;&gt;90</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2364.35,-1055.91C2374.06,-1044.43 2384.63,-1031.94 2394.36,-1020.44\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2397.15,-1022.56 2400.94,-1012.67 2391.8,-1018.04 2397.15,-1022.56\"/>\r\n",
       "</g>\r\n",
       "<!-- 93 -->\r\n",
       "<g id=\"node94\" class=\"node\"><title>93</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2819,-1377 2687,-1377 2687,-1294 2819,-1294 2819,-1377\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2753\" y=\"-1361.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SibSp &lt;= 0.435</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2753\" y=\"-1346.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.99</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2753\" y=\"-1331.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 75</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2753\" y=\"-1316.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [42, 33]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2753\" y=\"-1301.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 92&#45;&gt;93 -->\r\n",
       "<g id=\"edge93\" class=\"edge\"><title>92&#45;&gt;93</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2753,-1412.91C2753,-1404.65 2753,-1395.86 2753,-1387.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2756.5,-1387.02 2753,-1377.02 2749.5,-1387.02 2756.5,-1387.02\"/>\r\n",
       "</g>\r\n",
       "<!-- 102 -->\r\n",
       "<g id=\"node103\" class=\"node\"><title>102</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3033,-1377 2901,-1377 2901,-1294 3033,-1294 3033,-1377\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2967\" y=\"-1361.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Age &lt;= 53.645</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2967\" y=\"-1346.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.82</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2967\" y=\"-1331.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 47</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2967\" y=\"-1316.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [35, 12]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2967\" y=\"-1301.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 92&#45;&gt;102 -->\r\n",
       "<g id=\"edge102\" class=\"edge\"><title>92&#45;&gt;102</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2819.25,-1417.28C2842.21,-1404.73 2868.12,-1390.56 2891.76,-1377.63\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2893.6,-1380.62 2900.7,-1372.75 2890.25,-1374.47 2893.6,-1380.62\"/>\r\n",
       "</g>\r\n",
       "<!-- 94 -->\r\n",
       "<g id=\"node95\" class=\"node\"><title>94</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2755,-1258 2623,-1258 2623,-1175 2755,-1175 2755,-1258\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2689\" y=\"-1242.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3 &lt;= &#45;0.041</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2689\" y=\"-1227.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.977</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2689\" y=\"-1212.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 56</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2689\" y=\"-1197.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [33, 23]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2689\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 93&#45;&gt;94 -->\r\n",
       "<g id=\"edge94\" class=\"edge\"><title>93&#45;&gt;94</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2730.8,-1293.91C2726.03,-1285.2 2720.94,-1275.9 2716.02,-1266.89\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2719.03,-1265.11 2711.17,-1258.02 2712.89,-1268.47 2719.03,-1265.11\"/>\r\n",
       "</g>\r\n",
       "<!-- 101 -->\r\n",
       "<g id=\"node102\" class=\"node\"><title>101</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2883,-1250.5 2773,-1250.5 2773,-1182.5 2883,-1182.5 2883,-1250.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2828\" y=\"-1235.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.998</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2828\" y=\"-1220.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 19</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2828\" y=\"-1205.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [9, 10]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2828\" y=\"-1190.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 93&#45;&gt;101 -->\r\n",
       "<g id=\"edge101\" class=\"edge\"><title>93&#45;&gt;101</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2779.02,-1293.91C2786.24,-1282.65 2794.08,-1270.42 2801.33,-1259.11\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2804.29,-1260.97 2806.74,-1250.67 2798.4,-1257.2 2804.29,-1260.97\"/>\r\n",
       "</g>\r\n",
       "<!-- 95 -->\r\n",
       "<g id=\"node96\" class=\"node\"><title>95</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2762,-1139 2616,-1139 2616,-1056 2762,-1056 2762,-1139\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2689\" y=\"-1123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Embarked_C &lt;= 0.887</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2689\" y=\"-1108.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.938</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2689\" y=\"-1093.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 31</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2689\" y=\"-1078.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [20, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2689\" y=\"-1063.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 94&#45;&gt;95 -->\r\n",
       "<g id=\"edge95\" class=\"edge\"><title>94&#45;&gt;95</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2689,-1174.91C2689,-1166.65 2689,-1157.86 2689,-1149.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2692.5,-1149.02 2689,-1139.02 2685.5,-1149.02 2692.5,-1149.02\"/>\r\n",
       "</g>\r\n",
       "<!-- 98 -->\r\n",
       "<g id=\"node99\" class=\"node\"><title>98</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2948.5,-1139 2809.5,-1139 2809.5,-1056 2948.5,-1056 2948.5,-1139\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2879\" y=\"-1123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Embarked_C &lt;= 0.74</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2879\" y=\"-1108.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.999</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2879\" y=\"-1093.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 25</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2879\" y=\"-1078.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [13, 12]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2879\" y=\"-1063.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 94&#45;&gt;98 -->\r\n",
       "<g id=\"edge98\" class=\"edge\"><title>94&#45;&gt;98</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2754.92,-1174.91C2770.84,-1165.11 2787.96,-1154.56 2804.25,-1144.53\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2806.52,-1147.24 2813.2,-1139.02 2802.85,-1141.28 2806.52,-1147.24\"/>\r\n",
       "</g>\r\n",
       "<!-- 96 -->\r\n",
       "<g id=\"node97\" class=\"node\"><title>96</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2645,-1012.5 2513,-1012.5 2513,-944.5 2645,-944.5 2645,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2579\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 1.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2579\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 18</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2579\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [9, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2579\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 95&#45;&gt;96 -->\r\n",
       "<g id=\"edge96\" class=\"edge\"><title>95&#45;&gt;96</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2650.84,-1055.91C2639.94,-1044.32 2628.07,-1031.7 2617.18,-1020.11\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2619.58,-1017.56 2610.18,-1012.67 2614.48,-1022.35 2619.58,-1017.56\"/>\r\n",
       "</g>\r\n",
       "<!-- 97 -->\r\n",
       "<g id=\"node98\" class=\"node\"><title>97</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2795,-1012.5 2663,-1012.5 2663,-944.5 2795,-944.5 2795,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2729\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.619</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2729\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 13</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2729\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [11, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2729\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 95&#45;&gt;97 -->\r\n",
       "<g id=\"edge97\" class=\"edge\"><title>95&#45;&gt;97</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2702.88,-1055.91C2706.57,-1045.09 2710.58,-1033.38 2714.32,-1022.44\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2717.74,-1023.26 2717.66,-1012.67 2711.11,-1021 2717.74,-1023.26\"/>\r\n",
       "</g>\r\n",
       "<!-- 99 -->\r\n",
       "<g id=\"node100\" class=\"node\"><title>99</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2945,-1012.5 2813,-1012.5 2813,-944.5 2945,-944.5 2945,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2879\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.837</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2879\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 15</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2879\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [11, 4]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2879\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 98&#45;&gt;99 -->\r\n",
       "<g id=\"edge99\" class=\"edge\"><title>98&#45;&gt;99</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2879,-1055.91C2879,-1045.2 2879,-1033.62 2879,-1022.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2882.5,-1022.67 2879,-1012.67 2875.5,-1022.67 2882.5,-1022.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 100 -->\r\n",
       "<g id=\"node101\" class=\"node\"><title>100</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3073,-1012.5 2963,-1012.5 2963,-944.5 3073,-944.5 3073,-1012.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3018\" y=\"-997.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.722</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3018\" y=\"-982.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3018\" y=\"-967.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [2, 8]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3018\" y=\"-952.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Survived</text>\r\n",
       "</g>\r\n",
       "<!-- 98&#45;&gt;100 -->\r\n",
       "<g id=\"edge100\" class=\"edge\"><title>98&#45;&gt;100</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2927.23,-1055.91C2941.38,-1043.99 2956.85,-1030.98 2970.93,-1019.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2973.2,-1021.78 2978.6,-1012.67 2968.69,-1016.43 2973.2,-1021.78\"/>\r\n",
       "</g>\r\n",
       "<!-- 103 -->\r\n",
       "<g id=\"node104\" class=\"node\"><title>103</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3033,-1250.5 2901,-1250.5 2901,-1182.5 3033,-1182.5 3033,-1250.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2967\" y=\"-1235.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.943</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2967\" y=\"-1220.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 25</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2967\" y=\"-1205.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [16, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2967\" y=\"-1190.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 102&#45;&gt;103 -->\r\n",
       "<g id=\"edge103\" class=\"edge\"><title>102&#45;&gt;103</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2967,-1293.91C2967,-1283.2 2967,-1271.62 2967,-1260.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2970.5,-1260.67 2967,-1250.67 2963.5,-1260.67 2970.5,-1260.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 104 -->\r\n",
       "<g id=\"node105\" class=\"node\"><title>104</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3183,-1258 3051,-1258 3051,-1175 3183,-1175 3183,-1258\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3117\" y=\"-1242.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1 &lt;= 0.206</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3117\" y=\"-1227.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.575</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3117\" y=\"-1212.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 22</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3117\" y=\"-1197.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [19, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3117\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 102&#45;&gt;104 -->\r\n",
       "<g id=\"edge104\" class=\"edge\"><title>102&#45;&gt;104</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3019.04,-1293.91C3031.26,-1284.38 3044.37,-1274.15 3056.91,-1264.37\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3059.32,-1266.93 3065.05,-1258.02 3055.01,-1261.41 3059.32,-1266.93\"/>\r\n",
       "</g>\r\n",
       "<!-- 105 -->\r\n",
       "<g id=\"node106\" class=\"node\"><title>105</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3155,-1131.5 3023,-1131.5 3023,-1063.5 3155,-1063.5 3155,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3089\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.439</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3089\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 11</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3089\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [10, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3089\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 104&#45;&gt;105 -->\r\n",
       "<g id=\"edge105\" class=\"edge\"><title>104&#45;&gt;105</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3107.29,-1174.91C3104.7,-1164.09 3101.89,-1152.38 3099.28,-1141.44\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3102.67,-1140.58 3096.94,-1131.67 3095.86,-1142.21 3102.67,-1140.58\"/>\r\n",
       "</g>\r\n",
       "<!-- 106 -->\r\n",
       "<g id=\"node107\" class=\"node\"><title>106</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3305,-1131.5 3173,-1131.5 3173,-1063.5 3305,-1063.5 3305,-1131.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3239\" y=\"-1116.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.684</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3239\" y=\"-1101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 11</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3239\" y=\"-1086.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [9, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3239\" y=\"-1071.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = Not survived</text>\r\n",
       "</g>\r\n",
       "<!-- 104&#45;&gt;106 -->\r\n",
       "<g id=\"edge106\" class=\"edge\"><title>104&#45;&gt;106</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3159.33,-1174.91C3171.52,-1163.21 3184.82,-1150.46 3197,-1138.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3199.62,-1141.11 3204.42,-1131.67 3194.78,-1136.06 3199.62,-1141.11\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0xc3d3562320>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In newer versions of sklearn (from 0.21) we can use sklearn.tree.plot_tree or export_text\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "dot_data = export_graphviz(clf_dt, out_file=None,\n",
    "                           feature_names=train_df_num.drop([\"PassengerId\",\"Survived\"], axis=1).columns,\n",
    "                           class_names=['Not survived','Survived'], label='all')\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph\n",
    "# Value = [elements category 1 (Not Survived), elements category 2 (Survived)] --> addition=samples\n",
    "# class -> class with greatest number of samples\n",
    "# gini = 0 --> all the elements belong to one class\n",
    "# gini = 0.5 --> elements even distributed among classes (50% Survived, 50% Not Survived, in our example)\n",
    "# Always chooses the variable with the lowest gini in the root. And then the lowest of the rest of variables in the next level.\n",
    "# Example: 1 - (((383/622)^2) + ((239/622)^2)) = 0.473"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions in test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcion = 2\n",
    "\n",
    "# 1: logistic regression\n",
    "#2: neural network\n",
    "#3: SVM\n",
    "#4: random forest\n",
    "# 5: gradient boosting\n",
    "# 6: decision tree\n",
    "\n",
    "if opcion == 1:\n",
    "    clf = clf_lr\n",
    "    X_test_aux = X_test_sc\n",
    "    model=\"lr\"\n",
    "if opcion == 2:\n",
    "    clf = clf_nn\n",
    "    X_test_aux = X_test_sc\n",
    "    model=\"nn\"\n",
    "if opcion == 3:\n",
    "    clf = clf_svm\n",
    "    X_test_aux = X_test_sc\n",
    "    model=\"svm\"\n",
    "elif opcion == 4:\n",
    "    clf = clf_rf\n",
    "    X_test_aux = X_test\n",
    "    model=\"rf\"\n",
    "elif opcion == 5:\n",
    "    clf = clf_gb\n",
    "    X_test_aux = X_test\n",
    "    model=\"gb\"\n",
    "elif opcion == 6:\n",
    "    clf = clf_dt\n",
    "    X_test_aux = X_test\n",
    "    model=\"dt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob_surv_test=clf.predict_proba(X_test_aux) # Returns the probability between 0 and 1\n",
    "prob_surv_test=clf.predict(X_test_aux) # Returns 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame({\"PassengerId\":IDs_test,\n",
    "                             \"Survived\":prob_surv_test})\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "version=\"1.2\"\n",
    "predictions.to_csv('gender_submission_'+model+'_v'+version+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "\n",
    "v1\n",
    "* **Regresin Logstica:** 0.76076 ---> 76% de acierto (100 fallos)\n",
    "* **Neural Network:** 0.75598 ---> 76% de acierto (102 fallos)\n",
    "* **SVM:** 0.78468 ---> 78% de acierto (90 fallos)\n",
    "* **Random Forest (RF):** 0.73684 ---> 74% de acierto (110 fallos)\n",
    "* **Gradient Boosting (GB):** 0.78468 ---> 78% de acierto (90 fallos)\n",
    "* **Decision Tree:** 0.68899 ---> 69% de acierto (130 fallos)\n",
    "\n",
    "v1.1\n",
    "* **Regresin Logstica:** 0.75598 ---> 76% de acierto (102 fallos)\n",
    "* **Regresin Logstica:** 0.74641 ---> 75% de acierto (106 fallos)\n",
    "* **Neural Network:** 0.76555 ---> 76% de acierto (98 fallos)\n",
    "* **Neural Network:** 0.75119 ---> 75% de acierto (104 fallos)\n",
    "* **SVM:** 0.77990 ---> 78% de acierto (92 fallos)\n",
    "* **SVM:** 0.77511 ---> 77% de acierto (94 fallos)\n",
    "* **Random Forest (RF):** 0.74641 ---> 75% de acierto (106 fallos)\n",
    "* **Random Forest (RF):** 0.76555 ---> 76% de acierto (98 fallos)\n",
    "* **Gradient Boosting (GB):** 0.77511 ---> 77% de acierto (94 fallos)\n",
    "* **Gradient Boosting (GB):** 0.76555 ---> 76% de acierto (98 fallos)\n",
    "* **Decision Tree:** 0.67464 ---> 67% de acierto (136 fallos)\n",
    "* **Decision Tree:** 0.66507 ---> 66% de acierto (140 fallos)\n",
    "\n",
    "v1.2\n",
    "* **Regresin Logstica:** 0.77511 ---> 77% de acierto (94 fallos)\n",
    "* **Neural Network:** 0.76076 ---> 76% de acierto (100 fallos)\n",
    "* **SVM:** 0.77511 ---> 77% de acierto (94 fallos)\n",
    "* **Random Forest (RF):** 0.77990 ---> 78% de acierto (92 fallos)\n",
    "* **Gradient Boosting (GB):** 0.77272 ---> 77% de acierto (95 fallos)\n",
    "* **Gradient Boosting (GB): 0.79904** ---> 80% de acierto (84 fallos) --> cross_validate and taking the last one.\n",
    "* **Decision Tree:** 0.77990 ---> 78% de acierto (92 fallos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
